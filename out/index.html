<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/a34f9d1faa5f3315-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/heron-reflection.png"/><link rel="preload" as="image" href="/hero.JPG"/><link rel="preload" as="image" href="https://cdn.simpleicons.org/python/3776AB"/><link rel="preload" as="image" href="https://cdn.simpleicons.org/r/276DC3"/><link rel="preload" as="image" href="https://cdn.simpleicons.org/javascript/F7DF1E"/><link rel="preload" as="image" href="https://cdn.simpleicons.org/html5/E34F26"/><link rel="preload" as="image" href="https://cdn.simpleicons.org/react/61DAFB"/><link rel="preload" as="image" href="https://cdn.simpleicons.org/nextdotjs/000000"/><link rel="preload" as="image" href="https://cdn.simpleicons.org/tailwindcss/06B6D4"/><link rel="preload" as="image" href="https://cdn.simpleicons.org/django/092E20"/><link rel="stylesheet" href="/_next/static/css/730b9168ceaa3868.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/b3cbcd051438d1d5.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-84be5e7f048f0d69.js"/><script src="/_next/static/chunks/4bd1b696-f767626c8b2c1958.js" async=""></script><script src="/_next/static/chunks/684-44969689c1ecc70e.js" async=""></script><script src="/_next/static/chunks/main-app-44c3966afc00716c.js" async=""></script><script src="/_next/static/chunks/874-564943c90346e675.js" async=""></script><script src="/_next/static/chunks/497-8f454888f232b3fa.js" async=""></script><script src="/_next/static/chunks/766-98bd1540b448b2b9.js" async=""></script><script src="/_next/static/chunks/app/layout-83c85cf5db64605f.js" async=""></script><script src="/_next/static/chunks/663-bf703af64886d2e2.js" async=""></script><script src="/_next/static/chunks/app/page-b0a112a1deee7e7b.js" async=""></script><link rel="preload" as="image" href="https://cdn.simpleicons.org/supabase/3ECF8E"/><link rel="preload" as="image" href="https://cdn.simpleicons.org/vercel/000000"/><link rel="preload" as="image" href="https://cdn.simpleicons.org/python/150458"/><link rel="preload" as="image" href="https://cdn.simpleicons.org/plotly/3F4F75"/><meta name="next-size-adjust" content=""/><title>SingBirds | Environmental Tech Developer</title><meta name="description" content="Portfolio of SingBirds - Environmental Technologist and Developer"/><meta name="application-name" content="SingBirds"/><meta name="author" content="SingBirds"/><meta name="generator" content="v0.dev"/><link rel="shortcut icon" href="/favicon.ico"/><link rel="icon" href="/fairy-pitta.png"/><link rel="apple-touch-icon" href="/apple-icon.png"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_d65c78"><script>((e,t,r,n,o,a,i,l)=>{let u=document.documentElement,s=["light","dark"];function c(t){var r;(Array.isArray(e)?e:[e]).forEach(e=>{let r="class"===e,n=r&&a?o.map(e=>a[e]||e):o;r?(u.classList.remove(...n),u.classList.add(a&&a[t]?a[t]:t)):u.setAttribute(e,t)}),r=t,l&&s.includes(r)&&(u.style.colorScheme=r)}if(n)c(n);else try{let e=localStorage.getItem(t)||r,n=i&&"system"===e?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":e;c(n)}catch(e){}})("class","theme","light",null,["light","dark"],null,false,true)</script><nav class="fixed top-0 w-full z-50 transition-all duration-300 bg-transparent"><div class="container mx-auto px-4 py-4 flex justify-between items-center"><a class="flex items-center gap-2" href="/"><div class="w-8 h-8 rounded-full overflow-hidden mr-2"><img alt="SingBirds Logo" loading="lazy" width="32" height="32" decoding="async" data-nimg="1" class="w-full h-full object-cover" style="color:transparent" src="/pitta-gpt.png"/></div><span class="text-2xl font-bold gradient-text">SingBirds</span></a><div class="flex items-center gap-6"><button class="text-sm font-medium transition-colors text-white hover:text-sky-100 drop-shadow-[0_1px_1px_rgba(0,0,0,0.2)] font-semibold">About</button><button class="text-sm font-medium transition-colors text-white hover:text-sky-100 drop-shadow-[0_1px_1px_rgba(0,0,0,0.2)] font-semibold">Skills</button><a class="text-sm font-medium transition-colors text-white hover:text-sky-100 drop-shadow-[0_1px_1px_rgba(0,0,0,0.2)] font-semibold" href="/projects">Projects</a><a class="text-sm font-medium transition-colors text-white hover:text-sky-100 drop-shadow-[0_1px_1px_rgba(0,0,0,0.2)] font-semibold" href="/blog">Blog</a><button class="text-sm font-medium transition-colors text-white hover:text-sky-100 drop-shadow-[0_1px_1px_rgba(0,0,0,0.2)] font-semibold">Contact</button></div></div></nav><main class="relative overflow-hidden"><div class="fixed inset-0 w-full h-full z-[-1]"><div class="absolute inset-0 w-full h-full"><img alt="Bird floating on water" decoding="async" data-nimg="fill" class="object-cover" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/heron-reflection.png"/><div class="absolute inset-0 bg-gradient-to-b from-white/70 via-white/60 to-white/70 backdrop-blur-[2px]"></div></div><div class="absolute inset-0 bg-pattern opacity-20"></div></div><div class="scroll-indicator hidden lg:block"><div class="relative"><div class="scroll-indicator-dot active"></div></div><div class="relative"><div class="scroll-indicator-dot "></div></div><div class="relative"><div class="scroll-indicator-dot "></div></div><div class="relative"><div class="scroll-indicator-dot "></div></div><div class="relative"><div class="scroll-indicator-dot "></div></div></div><section id="about" class="snap-section min-h-screen relative"><div class="min-h-screen flex flex-col justify-center relative overflow-hidden pt-20"><div class="absolute inset-0 z-0"><img alt="mangrove blue flycatcher" decoding="async" data-nimg="fill" class="object-cover object-right" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/hero.JPG"/><div class="absolute inset-0 bg-gradient-to-r from-white/95 via-white/80 to-transparent"></div></div><div class="container mx-auto px-4 py-8 grid grid-cols-1 lg:grid-cols-2 gap-12 items-center relative z-10"><div class="flex flex-col gap-6" style="opacity:0;transform:translateY(20px)"><div><h1 class="text-4xl md:text-6xl font-bold mb-4"><span class="bg-clip-text text-transparent bg-gradient-to-r from-sky-400 to-blue-500 drop-shadow-[0_1px_1px_rgba(0,0,0,0.15)]">I</span> <span class="bg-clip-text text-transparent bg-gradient-to-br from-emerald-400 via-green-500 to-teal-400 drop-shadow-[0_1px_1px_rgba(0,0,0,0.15)]">Code</span> <span class="bg-clip-text text-transparent bg-gradient-to-br from-blue-400 via-indigo-500 to-purple-400 drop-shadow-[0_1px_1px_rgba(0,0,0,0.15)]">Birds</span></h1><h2 class="text-2xl md:text-2xl italic font-semibold text-sky-700">Environmental Tech Developer</h2></div><p class="text-lg font-medium text-sky-800 max-w-xl leading-relaxed">Birdsong, sightings, and behavior—mapped, analyzed, and reimagined through digital tools. Rooted in avian ethology and based in Singapore, this work bridges ecological insight with interactive design.</p><div class="flex flex-wrap gap-4"><a href="#projects" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 text-primary-foreground h-10 px-4 py-2 bg-sky-500 hover:bg-sky-600">View My Work</a><a href="#contact" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 border hover:bg-accent h-10 px-4 py-2 border-sky-300 text-sky-500 hover:text-sky-600 hover:border-sky-400 bg-white/20 backdrop-blur-sm">Get In Touch</a><a href="#contact" class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 border hover:bg-accent h-10 px-4 py-2 border-blue-300 text-blue-500 hover:text-blue-600 hover:border-blue-400 bg-white/20 backdrop-blur-sm"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-bell h-4 w-4 mr-2"><path d="M6 8a6 6 0 0 1 12 0c0 7 3 9 3 9H3s3-2 3-9"></path><path d="M10.3 21a1.94 1.94 0 0 0 3.4 0"></path></svg>Subscribe</a></div></div><div class="relative aspect-square max-w-md mx-auto hidden lg:block" style="opacity:0;transform:scale(0.9)"><div class="absolute inset-0 bg-white/20 backdrop-blur-sm rounded-2xl shadow-xl overflow-hidden"><div class="relative z-10 h-full flex flex-col items-center justify-center p-6"><div class="w-full max-w-[280px] h-auto relative mb-6 floating"><img alt="Digital Bird Illustration" loading="lazy" width="280" height="200" decoding="async" data-nimg="1" class="object-contain" style="color:transparent" src="/tech-bird-illustration.png"/></div><p class="text-sky-800/80 text-center text-sm italic font-medium">&quot;Harmonizing the natural world with digital innovation&quot;</p></div></div></div></div><div class="absolute bottom-10 left-1/2 transform -translate-x-1/2 animate-bounce z-10"><button class="inline-flex items-center justify-center gap-2 whitespace-nowrap text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 hover:text-accent-foreground bg-white/20 backdrop-blur-sm hover:bg-white/30 rounded-full w-12 h-12"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-down h-6 w-6"><path d="M12 5v14"></path><path d="m19 12-7 7-7-7"></path></svg></button></div></div></section><section id="skills" class="snap-section min-h-screen relative"><div class="min-h-screen py-20 relative overflow-hidden flex items-center"><div class="container mx-auto px-4 relative z-10"><div class="text-center mb-12" style="opacity:0;transform:translateY(20px)"><h2 class="text-3xl font-bold mb-4 text-sky-800">Skills &amp; Expertise</h2><p class="text-muted-foreground text-sky-600 max-w-2xl mx-auto">My interdisciplinary background allows me to approach problems from multiple angles, combining technical skills with environmental knowledge.</p></div><div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6"><div class="group" style="opacity:0;transform:translateY(20px)"><div class="rounded-lg border bg-card text-card-foreground shadow-sm h-full relative overflow-hidden transition-all duration-300 transform hover:shadow-lg border-transparent"><div class="absolute inset-0 bg-gradient-to-br from-blue-500 to-indigo-600 opacity-0 group-hover:opacity-10 transition-opacity duration-500"></div><div class="absolute -right-6 -top-6 w-24 h-24 rounded-full bg-gradient-to-br from-white/5 to-white/20 blur-xl"></div><div class="absolute -left-10 -bottom-10 w-40 h-40 rounded-full bg-gradient-to-tr from-white/5 to-white/10 blur-xl"></div><div class="p-6 relative z-10"><div class="flex items-center gap-4 mb-6 pb-4 border-b border-blue-300 transition-colors duration-300"><div class="w-12 h-12 rounded-lg flex items-center justify-center group-hover:bg-blue-50 bg-white/80 transition-colors duration-300"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-code-xml h-8 w-8 text-blue-500"><path d="m18 16 4-4-4-4"></path><path d="m6 8-4 4 4 4"></path><path d="m14.5 4-5 16"></path></svg></div><h3 class="text-xl font-bold text-blue-500">Programming Languages</h3></div><ul class="space-y-5"><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><img src="https://cdn.simpleicons.org/python/3776AB" alt="Python" class="w-5 h-5 group-hover/item:scale-110 transition-transform duration-300"/></div></div><div><span class="font-semibold text-blue-500">Python</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Data processing, Web development (Django)</p></div></li><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><img src="https://cdn.simpleicons.org/r/276DC3" alt="R" class="w-5 h-5 group-hover/item:scale-110 transition-transform duration-300"/></div></div><div><span class="font-semibold text-blue-500">R</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Statistical analysis, visualization, research</p></div></li><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><img src="https://cdn.simpleicons.org/javascript/F7DF1E" alt="JavaScript" class="w-5 h-5 group-hover/item:scale-110 transition-transform duration-300"/></div></div><div><span class="font-semibold text-blue-500">JavaScript</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Interactive web development</p></div></li><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><img src="https://cdn.simpleicons.org/html5/E34F26" alt="HTML/CSS" class="w-5 h-5 group-hover/item:scale-110 transition-transform duration-300"/></div></div><div><span class="font-semibold text-blue-500">HTML/CSS</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Frontend fundamentals</p></div></li></ul><div class="absolute bottom-3 right-3 w-16 h-16 rounded-full bg-gradient-to-br from-blue-500 to-indigo-600 opacity-0 group-hover:opacity-10 transition-all duration-500 transform group-hover:scale-150"></div></div></div></div><div class="group" style="opacity:0;transform:translateY(20px)"><div class="rounded-lg border bg-card text-card-foreground shadow-sm h-full relative overflow-hidden transition-all duration-300 transform hover:shadow-lg border-transparent"><div class="absolute inset-0 bg-gradient-to-br from-purple-500 to-pink-600 opacity-0 group-hover:opacity-10 transition-opacity duration-500"></div><div class="absolute -right-6 -top-6 w-24 h-24 rounded-full bg-gradient-to-br from-white/5 to-white/20 blur-xl"></div><div class="absolute -left-10 -bottom-10 w-40 h-40 rounded-full bg-gradient-to-tr from-white/5 to-white/10 blur-xl"></div><div class="p-6 relative z-10"><div class="flex items-center gap-4 mb-6 pb-4 border-b border-purple-300 transition-colors duration-300"><div class="w-12 h-12 rounded-lg flex items-center justify-center group-hover:bg-purple-50 bg-white/80 transition-colors duration-300"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-panels-top-left h-8 w-8 text-purple-500"><rect width="18" height="18" x="3" y="3" rx="2"></rect><path d="M3 9h18"></path><path d="M9 21V9"></path></svg></div><h3 class="text-xl font-bold text-purple-500">Frameworks &amp; Libraries</h3></div><ul class="space-y-5"><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><img src="https://cdn.simpleicons.org/react/61DAFB" alt="React" class="w-5 h-5 group-hover/item:scale-110 transition-transform duration-300"/></div></div><div><span class="font-semibold text-purple-500">React</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Component-based frontend development</p></div></li><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><img src="https://cdn.simpleicons.org/nextdotjs/000000" alt="Next.js" class="w-5 h-5 group-hover/item:scale-110 transition-transform duration-300"/></div></div><div><span class="font-semibold text-purple-500">Next.js</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Full-stack React framework with routing &amp; SSR/ISR</p></div></li><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><img src="https://cdn.simpleicons.org/tailwindcss/06B6D4" alt="Tailwind CSS" class="w-5 h-5 group-hover/item:scale-110 transition-transform duration-300"/></div></div><div><span class="font-semibold text-purple-500">Tailwind CSS</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Utility-first CSS framework for responsive design</p></div></li><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><img src="https://cdn.simpleicons.org/django/092E20" alt="Django" class="w-5 h-5 group-hover/item:scale-110 transition-transform duration-300"/></div></div><div><span class="font-semibold text-purple-500">Django</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Web apps &amp; API development</p></div></li></ul><div class="absolute bottom-3 right-3 w-16 h-16 rounded-full bg-gradient-to-br from-purple-500 to-pink-600 opacity-0 group-hover:opacity-10 transition-all duration-500 transform group-hover:scale-150"></div></div></div></div><div class="group" style="opacity:0;transform:translateY(20px)"><div class="rounded-lg border bg-card text-card-foreground shadow-sm h-full relative overflow-hidden transition-all duration-300 transform hover:shadow-lg border-transparent"><div class="absolute inset-0 bg-gradient-to-br from-cyan-500 to-blue-600 opacity-0 group-hover:opacity-10 transition-opacity duration-500"></div><div class="absolute -right-6 -top-6 w-24 h-24 rounded-full bg-gradient-to-br from-white/5 to-white/20 blur-xl"></div><div class="absolute -left-10 -bottom-10 w-40 h-40 rounded-full bg-gradient-to-tr from-white/5 to-white/10 blur-xl"></div><div class="p-6 relative z-10"><div class="flex items-center gap-4 mb-6 pb-4 border-b border-cyan-300 transition-colors duration-300"><div class="w-12 h-12 rounded-lg flex items-center justify-center group-hover:bg-cyan-50 bg-white/80 transition-colors duration-300"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-cloud h-8 w-8 text-cyan-500"><path d="M17.5 19H9a7 7 0 1 1 6.71-9h1.79a4.5 4.5 0 1 1 0 9Z"></path></svg></div><h3 class="text-xl font-bold text-cyan-500">Backend / Cloud Services</h3></div><ul class="space-y-5"><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><img src="https://cdn.simpleicons.org/supabase/3ECF8E" alt="Supabase" class="w-5 h-5 group-hover/item:scale-110 transition-transform duration-300"/></div></div><div><span class="font-semibold text-cyan-500">Supabase</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Backend-as-a-Service: authentication, database, storage</p></div></li><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-server h-5 w-5 text-orange-500"><rect width="20" height="8" x="2" y="2" rx="2" ry="2"></rect><rect width="20" height="8" x="2" y="14" rx="2" ry="2"></rect><line x1="6" x2="6.01" y1="6" y2="6"></line><line x1="6" x2="6.01" y1="18" y2="18"></line></svg></div></div><div><span class="font-semibold text-cyan-500">AWS</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Cloud infrastructure setup, server deployment, and scaling</p></div></li><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><img src="https://cdn.simpleicons.org/vercel/000000" alt="Vercel" class="w-5 h-5 group-hover/item:scale-110 transition-transform duration-300"/></div></div><div><span class="font-semibold text-cyan-500">Vercel</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Frontend hosting and CI/CD for React &amp; Next.js</p></div></li></ul><div class="absolute bottom-3 right-3 w-16 h-16 rounded-full bg-gradient-to-br from-cyan-500 to-blue-600 opacity-0 group-hover:opacity-10 transition-all duration-500 transform group-hover:scale-150"></div></div></div></div><div class="group" style="opacity:0;transform:translateY(20px)"><div class="rounded-lg border bg-card text-card-foreground shadow-sm h-full relative overflow-hidden transition-all duration-300 transform hover:shadow-lg border-transparent"><div class="absolute inset-0 bg-gradient-to-br from-green-500 to-emerald-600 opacity-0 group-hover:opacity-10 transition-opacity duration-500"></div><div class="absolute -right-6 -top-6 w-24 h-24 rounded-full bg-gradient-to-br from-white/5 to-white/20 blur-xl"></div><div class="absolute -left-10 -bottom-10 w-40 h-40 rounded-full bg-gradient-to-tr from-white/5 to-white/10 blur-xl"></div><div class="p-6 relative z-10"><div class="flex items-center gap-4 mb-6 pb-4 border-b border-green-300 transition-colors duration-300"><div class="w-12 h-12 rounded-lg flex items-center justify-center group-hover:bg-green-50 bg-white/80 transition-colors duration-300"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chart-no-axes-column-increasing h-8 w-8 text-green-500"><line x1="12" x2="12" y1="20" y2="10"></line><line x1="18" x2="18" y1="20" y2="4"></line><line x1="6" x2="6" y1="20" y2="16"></line></svg></div><h3 class="text-xl font-bold text-green-500">Data Analysis</h3></div><ul class="space-y-5"><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><img src="https://cdn.simpleicons.org/python/150458" alt="Python" class="w-5 h-5 group-hover/item:scale-110 transition-transform duration-300"/></div></div><div><span class="font-semibold text-green-500">Python</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Experienced in data cleaning, analysis, and basic machine learning using Python</p></div></li><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><img src="https://cdn.simpleicons.org/r/276DC3" alt="RStudio" class="w-5 h-5 group-hover/item:scale-110 transition-transform duration-300"/></div></div><div><span class="font-semibold text-green-500">RStudio</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Skilled in statistical analysis and data visualization using R</p></div></li><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><img src="https://cdn.simpleicons.org/plotly/3F4F75" alt="Data Visualization" class="w-5 h-5 group-hover/item:scale-110 transition-transform duration-300"/></div></div><div><span class="font-semibold text-green-500">Data Visualization</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Creating insightful visualizations with various libraries</p></div></li></ul><div class="absolute bottom-3 right-3 w-16 h-16 rounded-full bg-gradient-to-br from-green-500 to-emerald-600 opacity-0 group-hover:opacity-10 transition-all duration-500 transform group-hover:scale-150"></div></div></div></div><div class="group" style="opacity:0;transform:translateY(20px)"><div class="rounded-lg border bg-card text-card-foreground shadow-sm h-full relative overflow-hidden transition-all duration-300 transform hover:shadow-lg border-transparent"><div class="absolute inset-0 bg-gradient-to-br from-amber-500 to-orange-600 opacity-0 group-hover:opacity-10 transition-opacity duration-500"></div><div class="absolute -right-6 -top-6 w-24 h-24 rounded-full bg-gradient-to-br from-white/5 to-white/20 blur-xl"></div><div class="absolute -left-10 -bottom-10 w-40 h-40 rounded-full bg-gradient-to-tr from-white/5 to-white/10 blur-xl"></div><div class="p-6 relative z-10"><div class="flex items-center gap-4 mb-6 pb-4 border-b border-amber-300 transition-colors duration-300"><div class="w-12 h-12 rounded-lg flex items-center justify-center group-hover:bg-amber-50 bg-white/80 transition-colors duration-300"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-globe h-8 w-8 text-amber-500"><circle cx="12" cy="12" r="10"></circle><path d="M12 2a14.5 14.5 0 0 0 0 20 14.5 14.5 0 0 0 0-20"></path><path d="M2 12h20"></path></svg></div><h3 class="text-xl font-bold text-amber-500">Languages</h3></div><ul class="space-y-5"><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><svg viewBox="0 0 24 24" width="20" height="20" fill="none" xmlns="http://www.w3.org/2000/svg" class="text-blue-600"><path d="M21 12C21 16.9706 16.9706 21 12 21C7.02944 21 3 16.9706 3 12C3 7.02944 7.02944 3 12 3C16.9706 3 21 7.02944 21 12Z" stroke="currentColor" stroke-width="2"></path><path d="M3.5 12H20.5" stroke="currentColor" stroke-width="2" stroke-linecap="round"></path><path d="M12 3.5V20.5" stroke="currentColor" stroke-width="2" stroke-linecap="round"></path><path d="M18.5 7L5.5 17" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path><path d="M18.5 17L5.5 7" stroke="currentColor" stroke-width="1.5" stroke-linecap="round"></path></svg></div></div><div><span class="font-semibold text-amber-500">English</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Fluent</p></div></li><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><svg viewBox="0 0 24 24" width="20" height="20" fill="none" xmlns="http://www.w3.org/2000/svg" class="text-red-600"><circle cx="12" cy="12" r="9" stroke="currentColor" stroke-width="2"></circle><circle cx="12" cy="12" r="4" fill="currentColor"></circle></svg></div></div><div><span class="font-semibold text-amber-500">Japanese</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Native</p></div></li></ul><div class="absolute bottom-3 right-3 w-16 h-16 rounded-full bg-gradient-to-br from-amber-500 to-orange-600 opacity-0 group-hover:opacity-10 transition-all duration-500 transform group-hover:scale-150"></div></div></div></div><div class="group" style="opacity:0;transform:translateY(20px)"><div class="rounded-lg border bg-card text-card-foreground shadow-sm h-full relative overflow-hidden transition-all duration-300 transform hover:shadow-lg border-transparent"><div class="absolute inset-0 bg-gradient-to-br from-emerald-500 to-green-600 opacity-0 group-hover:opacity-10 transition-opacity duration-500"></div><div class="absolute -right-6 -top-6 w-24 h-24 rounded-full bg-gradient-to-br from-white/5 to-white/20 blur-xl"></div><div class="absolute -left-10 -bottom-10 w-40 h-40 rounded-full bg-gradient-to-tr from-white/5 to-white/10 blur-xl"></div><div class="p-6 relative z-10"><div class="flex items-center gap-4 mb-6 pb-4 border-b border-emerald-300 transition-colors duration-300"><div class="w-12 h-12 rounded-lg flex items-center justify-center group-hover:bg-emerald-50 bg-white/80 transition-colors duration-300"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-leaf h-8 w-8 text-emerald-500"><path d="M11 20A7 7 0 0 1 9.8 6.1C15.5 5 17 4.48 19 2c1 2 2 4.18 2 8 0 5.5-4.78 10-10 10Z"></path><path d="M2 21c0-3 1.85-5.36 5.08-6C9.5 14.52 12 13 13 12"></path></svg></div><h3 class="text-xl font-bold text-emerald-500">Environmental Science</h3></div><ul class="space-y-5"><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><svg viewBox="0 0 24 24" width="20" height="20" fill="none" xmlns="http://www.w3.org/2000/svg" class="text-emerald-600"><path d="M12 6C14.2091 6 16 7.79086 16 10C16 12.2091 14.2091 14 12 14C9.79086 14 8 12.2091 8 10C8 7.79086 9.79086 6 12 6Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M16 15C16 16.6569 14.2091 18 12 18C9.79086 18 8 16.6569 8 15" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M3 10.5C3 9.67157 3.67157 9 4.5 9C5.32843 9 6 9.67157 6 10.5C6 11.3284 5.32843 12 4.5 12C3.67157 12 3 11.3284 3 10.5Z" stroke="currentColor" stroke-width="2"></path><path d="M18 10.5C18 9.67157 18.6716 9 19.5 9C20.3284 9 21 9.67157 21 10.5C21 11.3284 20.3284 12 19.5 12C18.6716 12 18 11.3284 18 10.5Z" stroke="currentColor" stroke-width="2"></path><path d="M6 10L8 10" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M16 10L18 10" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M12 18V21" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M12 21H15" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M12 21H9" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M12 3L14 5L12 6L10 5L12 3Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></div><div><span class="font-semibold text-emerald-500">Avian Ethology</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Research and observation of bird behavior</p></div></li><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><svg viewBox="0 0 24 24" width="20" height="20" fill="none" xmlns="http://www.w3.org/2000/svg" class="text-emerald-600"><path d="M9 20H7C5.89543 20 5 19.1046 5 18V15M9 20H15M9 20V15M15 20H17C18.1046 20 19 19.1046 19 18V15M15 20V15M5 15H9M5 15V9C5 7.89543 5.89543 7 7 7H9M19 15H15M19 15V9C19 7.89543 18.1046 7 17 7H15M9 15V7M9 7H15M15 7V15M15 15H9" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M12 7V4" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M10 5H14" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></div><div><span class="font-semibold text-emerald-500">Ecology</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Environmental systems analysis and monitoring</p></div></li><li class="flex items-start gap-3 group/item"><div class="flex-shrink-0 mt-0.5"><div class="w-8 h-8 flex items-center justify-center bg-white/80 rounded-md shadow-sm group-hover/item:shadow-md transition-all duration-300"><svg viewBox="0 0 24 24" width="20" height="20" fill="none" xmlns="http://www.w3.org/2000/svg" class="text-emerald-600"><path d="M12 12V21" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M16 16V17" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M8 16V17" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M12 12C14.2091 12 16 10.2091 16 8C16 5.79086 14.2091 4 12 4C9.79086 4 8 5.79086 8 8C8 10.2091 9.79086 12 12 12Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M3 10L5 9" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M3 14L5 15" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M3 18L5 17" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 10L19 9" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 14L19 15" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path><path d="M21 18L19 17" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path></svg></div></div><div><span class="font-semibold text-emerald-500">Bioacoustics</span><p class="text-sm text-muted-foreground group-hover/item:text-gray-700 dark:group-hover/item:text-gray-300 transition-colors duration-300">Acoustic monitoring of animal behavior</p></div></li></ul><div class="absolute bottom-3 right-3 w-16 h-16 rounded-full bg-gradient-to-br from-emerald-500 to-green-600 opacity-0 group-hover:opacity-10 transition-all duration-500 transform group-hover:scale-150"></div></div></div></div></div></div></div></section><section id="projects" class="snap-section min-h-screen relative"><div class="min-h-screen py-20 relative overflow-hidden flex items-center"><div class="container mx-auto px-4 relative z-10"><div class="text-center mb-12" style="opacity:0;transform:translateY(20px)"><h2 class="text-3xl font-bold mb-4 text-sky-800">Featured Projects</h2><p class="text-sky-600 max-w-2xl mx-auto">A collection of work that demonstrates the intersection of environmental science and technology.</p></div><div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8"><div style="opacity:0;transform:translateY(20px)"><div class="rounded-lg border text-card-foreground shadow-sm hover-card h-full flex flex-col overflow-hidden bg-white/85 backdrop-blur-sm border-transparent"><div class="aspect-video relative overflow-hidden"><img alt="Building My Portfolio in Two Days" loading="lazy" decoding="async" data-nimg="fill" class="object-cover transition-transform duration-500 hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/projects/Portfolio/portfolio_main.png"/></div><div class="p-6 flex-grow"><a class="hover:text-sky-600 transition-colors" href="/projects/Portfolio"><h3 class="text-xl font-semibold mb-2">Building My Portfolio in Two Days</h3></a><p class="text-muted-foreground mb-4">I built my personal portfolio website in two days, focusing on a clear and maintainable design without unnecessary complexity.</p><div class="flex flex-wrap gap-2"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80">Web App</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80">Next.js</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80">AWS</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80">Amplify</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80">v0</div></div></div><div class="items-center p-6 px-6 pb-6 pt-0 flex flex-wrap gap-2"><a href="https://github.com/fairy-pitta/singbirds-portfolio" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center gap-2 whitespace-nowrap font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 border bg-background hover:text-accent-foreground rounded-md border-sky-300 text-sky-600 hover:bg-sky-50 text-xs px-2 h-8"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-3.5 w-3.5 mr-1"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg>Code</a><a href="https://singbirds.net" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center gap-2 whitespace-nowrap font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 border bg-background hover:text-accent-foreground rounded-md border-sky-300 text-sky-600 hover:bg-sky-50 text-xs px-2 h-8"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3.5 w-3.5 mr-1"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>Demo</a><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 rounded-md bg-sky-500 hover:bg-sky-600 text-white ml-auto text-xs px-2 h-8" href="/projects/Portfolio"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-eye h-3.5 w-3.5 mr-1"><path d="M2.062 12.348a1 1 0 0 1 0-.696 10.75 10.75 0 0 1 19.876 0 1 1 0 0 1 0 .696 10.75 10.75 0 0 1-19.876 0"></path><circle cx="12" cy="12" r="3"></circle></svg>Details</a></div></div></div><div style="opacity:0;transform:translateY(20px)"><div class="rounded-lg border text-card-foreground shadow-sm hover-card h-full flex flex-col overflow-hidden bg-white/85 backdrop-blur-sm border-transparent"><div class="aspect-video relative overflow-hidden"><img alt="Learning Singapore’s Birds by Ear: A Look at the SingBirds Call Quiz" loading="lazy" decoding="async" data-nimg="fill" class="object-cover transition-transform duration-500 hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/projects/callquiz/CallQuiz_main.png"/></div><div class="p-6 flex-grow"><a class="hover:text-sky-600 transition-colors" href="/projects/SGBirdCall"><h3 class="text-xl font-semibold mb-2">Learning Singapore’s Birds by Ear: A Look at the SingBirds Call Quiz</h3></a><p class="text-muted-foreground mb-4">An interactive quiz web app to test out your bird call knowledge</p><div class="flex flex-wrap gap-2"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80">React</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80">Django</div><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 border-transparent bg-secondary text-secondary-foreground hover:bg-secondary/80">Birds</div></div></div><div class="items-center p-6 px-6 pb-6 pt-0 flex flex-wrap gap-2"><a href="https://github.com/fairy-pitta/Singbirds-frontend" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center gap-2 whitespace-nowrap font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 border bg-background hover:text-accent-foreground rounded-md border-sky-300 text-sky-600 hover:bg-sky-50 text-xs px-2 h-8"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-3.5 w-3.5 mr-1"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg>Code</a><a href="https://quiz.singbirds.net/" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center gap-2 whitespace-nowrap font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 border bg-background hover:text-accent-foreground rounded-md border-sky-300 text-sky-600 hover:bg-sky-50 text-xs px-2 h-8"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-external-link h-3.5 w-3.5 mr-1"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg>Demo</a><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 rounded-md bg-sky-500 hover:bg-sky-600 text-white ml-auto text-xs px-2 h-8" href="/projects/SGBirdCall"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-eye h-3.5 w-3.5 mr-1"><path d="M2.062 12.348a1 1 0 0 1 0-.696 10.75 10.75 0 0 1 19.876 0 1 1 0 0 1 0 .696 10.75 10.75 0 0 1-19.876 0"></path><circle cx="12" cy="12" r="3"></circle></svg>Details</a></div></div></div></div><div class="flex justify-center mt-10"><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 text-primary-foreground h-10 px-4 py-2 bg-sky-500 hover:bg-sky-600" href="/projects">View All Projects</a></div></div></div></section><section id="blog" class="snap-section min-h-screen relative"><div class="min-h-screen py-20 relative overflow-hidden flex items-center"><div class="container mx-auto px-4 relative z-10"><div class="text-center mb-12" style="opacity:0;transform:translateY(20px)"><h2 class="text-3xl font-bold mb-4 text-sky-800">Latest Articles</h2><p class="text-sky-600 max-w-2xl mx-auto">Thoughts, insights, and explorations at the intersection of environmental science and technology.</p></div><div class="relative px-12 md:px-16"><div class="flex overflow-x-auto pb-6 scrollbar-hide snap-x snap-mandatory scroll-smooth" style="scrollbar-width:none;-ms-overflow-style:none"><div class="flex-shrink-0 w-full md:w-[350px] px-3 snap-start" style="opacity:0;transform:translateY(20px)"><div class="rounded-lg border text-card-foreground shadow-sm hover-card h-full flex flex-col bg-white/85 backdrop-blur-sm border-transparent"><div class="aspect-video relative overflow-hidden"><img alt="Singapore - Challenges and Progress in Bioacoustics" loading="lazy" decoding="async" data-nimg="fill" class="object-cover transition-transform duration-500 hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/blogs/bird_call_singapore.png"/></div><div class="p-6 flex-grow"><div class="flex items-center gap-3 text-sm text-muted-foreground mb-3"><span class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-calendar h-4 w-4 mr-1"><path d="M8 2v4"></path><path d="M16 2v4"></path><rect width="18" height="18" x="3" y="4" rx="2"></rect><path d="M3 10h18"></path></svg>May 6, 2025</span><span class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-clock h-4 w-4 mr-1"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg>10 min read</span></div><a class="hover:text-sky-600 transition-colors" href="/blog/bird-sound-classification-in-singapore"><h3 class="text-xl font-semibold mb-2">Singapore - Challenges and Progress in Bioacoustics</h3></a><p class="text-muted-foreground mb-4 line-clamp-2">A quick look at the bioacoustics challenges in Singapore</p><div class="flex flex-wrap gap-2 mt-auto"><a href="/blog/tag/deep-research"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground hover:bg-sky-50 cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag h-3 w-3 mr-1"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>Deep Research</div></a><a href="/blog/tag/bioacoustics"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground hover:bg-sky-50 cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag h-3 w-3 mr-1"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>bioacoustics</div></a><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground">+<!-- -->1</div></div></div><div class="flex items-center p-6 px-6 pb-6 pt-0"><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 hover:bg-accent p-0 h-auto text-sky-500 hover:text-sky-600" href="/blog/bird-sound-classification-in-singapore">Read more <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right h-4 w-4 ml-1"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></a></div></div></div><div class="flex-shrink-0 w-full md:w-[350px] px-3 snap-start" style="opacity:0;transform:translateY(20px)"><div class="rounded-lg border text-card-foreground shadow-sm hover-card h-full flex flex-col bg-white/85 backdrop-blur-sm border-transparent"><div class="aspect-video relative overflow-hidden"><img alt="Approaches Bioacoutics via Data" loading="lazy" decoding="async" data-nimg="fill" class="object-cover transition-transform duration-500 hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/blogs/bird_call_illustration.png"/></div><div class="p-6 flex-grow"><div class="flex items-center gap-3 text-sm text-muted-foreground mb-3"><span class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-calendar h-4 w-4 mr-1"><path d="M8 2v4"></path><path d="M16 2v4"></path><rect width="18" height="18" x="3" y="4" rx="2"></rect><path d="M3 10h18"></path></svg>May 5, 2025</span><span class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-clock h-4 w-4 mr-1"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg>20 min read</span></div><a class="hover:text-sky-600 transition-colors" href="/blog/bird-sound-classification-in-data-sparse-regional-context"><h3 class="text-xl font-semibold mb-2">Approaches Bioacoutics via Data</h3></a><p class="text-muted-foreground mb-4 line-clamp-2">Bird Sound Classification in Data-Sparse Regional Contexts: Literature Review</p><div class="flex flex-wrap gap-2 mt-auto"><a href="/blog/tag/deep-research"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground hover:bg-sky-50 cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag h-3 w-3 mr-1"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>Deep Research</div></a><a href="/blog/tag/bioacoustics"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground hover:bg-sky-50 cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag h-3 w-3 mr-1"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>bioacoustics</div></a><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground">+<!-- -->1</div></div></div><div class="flex items-center p-6 px-6 pb-6 pt-0"><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 hover:bg-accent p-0 h-auto text-sky-500 hover:text-sky-600" href="/blog/bird-sound-classification-in-data-sparse-regional-context">Read more <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right h-4 w-4 ml-1"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></a></div></div></div><div class="flex-shrink-0 w-full md:w-[350px] px-3 snap-start" style="opacity:0;transform:translateY(20px)"><div class="rounded-lg border text-card-foreground shadow-sm hover-card h-full flex flex-col bg-white/85 backdrop-blur-sm border-transparent"><div class="aspect-video relative overflow-hidden"><img alt="New Technologies for Bird Acoustic Monitoring" loading="lazy" decoding="async" data-nimg="fill" class="object-cover transition-transform duration-500 hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/blogs/ecological-model-on-screen.png"/></div><div class="p-6 flex-grow"><div class="flex items-center gap-3 text-sm text-muted-foreground mb-3"><span class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-calendar h-4 w-4 mr-1"><path d="M8 2v4"></path><path d="M16 2v4"></path><rect width="18" height="18" x="3" y="4" rx="2"></rect><path d="M3 10h18"></path></svg>April 27, 2025</span><span class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-clock h-4 w-4 mr-1"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg>10 min read</span></div><a class="hover:text-sky-600 transition-colors" href="/blog/tools-for-bird-acoustic-monitoring"><h3 class="text-xl font-semibold mb-2">New Technologies for Bird Acoustic Monitoring</h3></a><p class="text-muted-foreground mb-4 line-clamp-2">Bird monitoring tools are transforming conservation across Southeast Asia</p><div class="flex flex-wrap gap-2 mt-auto"><a href="/blog/tag/deep-research"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground hover:bg-sky-50 cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag h-3 w-3 mr-1"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>Deep Research</div></a><a href="/blog/tag/bioacoustics"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground hover:bg-sky-50 cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag h-3 w-3 mr-1"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>bioacoustics</div></a></div></div><div class="flex items-center p-6 px-6 pb-6 pt-0"><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 hover:bg-accent p-0 h-auto text-sky-500 hover:text-sky-600" href="/blog/tools-for-bird-acoustic-monitoring">Read more <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right h-4 w-4 ml-1"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></a></div></div></div><div class="flex-shrink-0 w-full md:w-[350px] px-3 snap-start" style="opacity:0;transform:translateY(20px)"><div class="rounded-lg border text-card-foreground shadow-sm hover-card h-full flex flex-col bg-white/85 backdrop-blur-sm border-transparent"><div class="aspect-video relative overflow-hidden"><img alt="Changes in Bird Vocalization in City vs. Forest" loading="lazy" decoding="async" data-nimg="fill" class="object-cover transition-transform duration-500 hover:scale-105" style="position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent" src="/blogs/bird_calling.JPG"/></div><div class="p-6 flex-grow"><div class="flex items-center gap-3 text-sm text-muted-foreground mb-3"><span class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-calendar h-4 w-4 mr-1"><path d="M8 2v4"></path><path d="M16 2v4"></path><rect width="18" height="18" x="3" y="4" rx="2"></rect><path d="M3 10h18"></path></svg>April 26, 2025</span><span class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-clock h-4 w-4 mr-1"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg>10 min read</span></div><a class="hover:text-sky-600 transition-colors" href="/blog/change-in-bird-vocalization"><h3 class="text-xl font-semibold mb-2">Changes in Bird Vocalization in City vs. Forest</h3></a><p class="text-muted-foreground mb-4 line-clamp-2">A quick look at the changes in bird vocalizations between urban and forest</p><div class="flex flex-wrap gap-2 mt-auto"><a href="/blog/tag/deep-research"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground hover:bg-sky-50 cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag h-3 w-3 mr-1"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>Deep Research</div></a><a href="/blog/tag/bioacoustics"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground hover:bg-sky-50 cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag h-3 w-3 mr-1"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>bioacoustics</div></a></div></div><div class="flex items-center p-6 px-6 pb-6 pt-0"><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 hover:bg-accent p-0 h-auto text-sky-500 hover:text-sky-600" href="/blog/change-in-bird-vocalization">Read more <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-right h-4 w-4 ml-1"><path d="M5 12h14"></path><path d="m12 5 7 7-7 7"></path></svg></a></div></div></div></div><button class="absolute right-0 top-1/2 -translate-y-1/2 z-10 bg-sky-500 hover:bg-sky-600 text-white rounded-full p-3 shadow-lg transition-all duration-200 transform hover:scale-110" aria-label="Scroll right"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-chevron-right h-6 w-6"><path d="m9 18 6-6-6-6"></path></svg></button><div class="flex justify-center mt-6 gap-2"><button class="w-2 h-2 rounded-full transition-all bg-sky-500 w-4" aria-label="Go to page 1"></button><button class="w-2 h-2 rounded-full transition-all bg-sky-200 hover:bg-sky-300" aria-label="Go to page 2"></button></div></div><div class="flex justify-center mt-10"><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 text-primary-foreground h-10 px-4 py-2 bg-sky-500 hover:bg-sky-600" href="/blog">View All Articles</a></div></div></div></section><section id="contact" class="snap-section min-h-screen relative"><div class="min-h-screen py-20 relative overflow-hidden flex items-center"><div class="container mx-auto px-4 relative z-10"><div class="text-center mb-12" style="opacity:0;transform:translateY(20px)"><h2 class="text-3xl font-bold mb-4 text-sky-800">Connect With Me</h2><p class="text-sky-600 max-w-2xl mx-auto">Have a question or want to stay updated? Reach out or subscribe to my newsletter.</p></div><div class="grid grid-cols-1 lg:grid-cols-2 gap-8 max-w-5xl mx-auto"><div style="opacity:0;transform:translateX(-20px)"><div class="rounded-lg border text-card-foreground h-full border-sky-100 shadow-sm hover:shadow-md transition-shadow bg-white/85 backdrop-blur-sm"><div class="p-8"><div class="mb-6"><h2 class="text-2xl font-bold mb-2 text-sky-700">Get In Touch</h2><div class="w-12 h-1 bg-gradient-to-r from-sky-400 to-sky-500 rounded-full mb-4"></div><p class="text-muted-foreground">Have a question or want to collaborate? Send me a message and I&#x27;ll get back to you soon.</p></div><form class="space-y-5"><div><label for="name" class="text-sm font-medium block mb-1.5 text-gray-70">Name</label><input class="flex h-10 w-full rounded-md border bg-background px-3 py-2 text-base ring-offset-background file:border-0 file:bg-transparent file:text-sm file:font-medium file:text-foreground placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 md:text-sm border-sky-100 focus:border-sky-300" id="name" placeholder="Your name" required="" name="name" value=""/></div><div><label for="email" class="text-sm font-medium block mb-1.5 text-gray-700">Email</label><input type="email" class="flex h-10 w-full rounded-md border bg-background px-3 py-2 text-base ring-offset-background file:border-0 file:bg-transparent file:text-sm file:font-medium file:text-foreground placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 md:text-sm border-sky-100 focus:border-sky-300" id="email" placeholder="your.email@example.com" required="" name="email" value=""/></div><div><label for="message" class="text-sm font-medium block mb-1.5 text-gray-700">Message</label><textarea class="flex min-h-[80px] w-full rounded-md border bg-background px-3 py-2 text-base ring-offset-background placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 md:text-sm border-sky-100 focus:border-sky-300 resize-none" id="message" name="message" placeholder="Your message..." rows="4" required=""></textarea></div><button class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 bg-primary text-primary-foreground hover:bg-primary/90 h-10 px-4 py-2 w-full bg-gradient-to-r from-sky-500 to-sky-600 hover:from-sky-600 hover:to-sky-700 transition-all duration-300" type="submit"><span class="flex items-center gap-2"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-send h-4 w-4"><path d="M14.536 21.686a.5.5 0 0 0 .937-.024l6.5-19a.496.496 0 0 0-.635-.635l-19 6.5a.5.5 0 0 0-.024.937l7.93 3.18a2 2 0 0 1 1.112 1.11z"></path><path d="m21.854 2.147-10.94 10.939"></path></svg>Send Message</span></button></form></div></div></div><div id="newsletter" style="opacity:0;transform:translateX(20px)"><div class="rounded-lg border text-card-foreground h-full border-sky-100 shadow-sm hover:shadow-md transition-shadow bg-white/85 backdrop-blur-sm"><div class="p-8"><div class="mb-6"><h2 class="text-2xl font-bold mb-2 text-sky-700">Stay Updated</h2><div class="w-12 h-1 bg-gradient-to-r from-sky-400 to-sky-500 rounded-full mb-4"></div><p class="text-muted-foreground">Subscribe to receive new articles, project updates, and environmental tech insights.</p></div><form class="space-y-5"><div><label for="newsletter-email" class="text-sm font-medium block mb-1.5 text-gray-700">Email Address</label><div class="relative"><input type="email" class="flex h-10 w-full rounded-md border bg-background px-3 py-2 text-base ring-offset-background file:border-0 file:bg-transparent file:text-sm file:font-medium file:text-foreground placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 md:text-sm pl-10 border-sky-100 focus:border-sky-300" id="newsletter-email" placeholder="your.email@example.com" required="" value=""/><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-bell absolute left-3 top-1/2 transform -translate-y-1/2 h-4 w-4 text-sky-400"><path d="M6 8a6 6 0 0 1 12 0c0 7 3 9 3 9H3s3-2 3-9"></path><path d="M10.3 21a1.94 1.94 0 0 0 3.4 0"></path></svg></div></div><button class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 bg-primary text-primary-foreground hover:bg-primary/90 h-10 px-4 py-2 w-full bg-gradient-to-r from-sky-500 to-sky-600 hover:from-sky-600 hover:to-sky-700 transition-all duration-300" type="submit"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-bell h-4 w-4 mr-2"><path d="M6 8a6 6 0 0 1 12 0c0 7 3 9 3 9H3s3-2 3-9"></path><path d="M10.3 21a1.94 1.94 0 0 0 3.4 0"></path></svg>Subscribe to Newsletter</button><p class="text-xs text-muted-foreground text-center mt-2">By subscribing, you agree to our<!-- --> <a href="/privacy" class="underline hover:text-sky-500">Privacy Policy</a>.</p></form></div></div></div></div></div></div></section></main><footer class="py-8 border-t"><div class="container mx-auto px-4"><div class="flex flex-col md:flex-row justify-between items-center gap-6"><div class="flex flex-col items-center md:items-start"><div class="flex items-center gap-2 mb-2"><div class="w-8 h-8 rounded-full overflow-hidden mr-2"><img alt="SingBirds Logo" loading="lazy" width="32" height="32" decoding="async" data-nimg="1" class="w-full h-full object-cover" style="color:transparent" src="/pitta-gpt.png"/></div><h3 class="text-xl font-bold gradient-text">SingBirds</h3></div><p class="text-sm text-muted-foreground text-center md:text-left">I Code Birds.</p></div><div class="flex gap-4"><a href="https://github.com/fairy-pitta" target="_blank" rel="noopener noreferrer" class="text-muted-foreground hover:text-sky-500 transition-colors" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-6 w-6"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a></div></div><div class="border-t mt-6 pt-6 flex flex-col md:flex-row justify-between items-center gap-4"><div class="text-sm text-muted-foreground">© <!-- -->2025<!-- --> SingBirds. All rights reserved.</div><div class="flex gap-6 text-sm"><a href="/privacy" class="text-muted-foreground hover:text-sky-500 transition-colors">Privacy Policy</a><a href="/terms" class="text-muted-foreground hover:text-sky-500 transition-colors">Terms of Service</a></div></div></div></footer><script src="/_next/static/chunks/webpack-84be5e7f048f0d69.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[9304,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"static/chunks/497-8f454888f232b3fa.js\",\"766\",\"static/chunks/766-98bd1540b448b2b9.js\",\"177\",\"static/chunks/app/layout-83c85cf5db64605f.js\"],\"ThemeProvider\"]\n3:I[9578,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"static/chunks/497-8f454888f232b3fa.js\",\"766\",\"static/chunks/766-98bd1540b448b2b9.js\",\"177\",\"static/chunks/app/layout-83c85cf5db64605f.js\"],\"default\"]\n4:I[7555,[],\"\"]\n5:I[1295,[],\"\"]\n6:I[3063,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"static/chunks/497-8f454888f232b3fa.js\",\"766\",\"static/chunks/766-98bd1540b448b2b9.js\",\"177\",\"static/chunks/app/layout-83c85cf5db64605f.js\"],\"Image\"]\n7:I[8659,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"static/chunks/497-8f454888f232b3fa.js\",\"663\",\"static/chunks/663-bf703af64886d2e2.js\",\"766\",\"static/chunks/766-98bd1540b448b2b9.js\",\"974\",\"static/chunks/app/page-b0a112a1deee7e7b.js\"],\"default\"]\n8:I[9483,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"static/chunks/497-8f454888f232b3fa.js\",\"663\",\"static/chunks/663-bf703af64886d2e2.js\",\"766\",\"static/chunks/766-98bd1540b448b2b9.js\",\"974\",\"static/chunks/app/page-b0a112a1deee7e7b.js\"],\"default\"]\n9:I[5316,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"static/chunks/497-8f454888f232b3fa.js\",\"663\",\"static/chunks/663-bf703af64886d2e2.js\",\"766\",\"static/chunks/766-98bd1540b448b2b9.js\",\"974\",\"static/chunks/app/page-b0a112a1deee7e7b.js\"],\"default\"]\na:I[7043,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"static/chunks/497-8f454888f232b3fa.js\",\"663\",\"static/chunks/663-bf703af64886d2e2.js\",\"766\",\"static/chunks/766-98bd1540b448b2b9.js\",\"974\",\"static/chunks/app/page-b0a112a1deee7e7b.js\"],\"default\"]\nb:I[8300,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"static/chunks/497-8f454888f232b3fa.js\",\"663\",\"static/chunks/663-bf703af64886d2e2.js\",\"766\",\"static/chunks/766-98bd1540b448b2b9.js\",\"974\",\"static/chunks/app/page-b0a112a1deee7e7b.js\"],\"default\"]\nc:I[1350,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"stat"])</script><script>self.__next_f.push([1,"ic/chunks/497-8f454888f232b3fa.js\",\"663\",\"static/chunks/663-bf703af64886d2e2.js\",\"766\",\"static/chunks/766-98bd1540b448b2b9.js\",\"974\",\"static/chunks/app/page-b0a112a1deee7e7b.js\"],\"default\"]\nf:I[5038,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"static/chunks/497-8f454888f232b3fa.js\",\"663\",\"static/chunks/663-bf703af64886d2e2.js\",\"766\",\"static/chunks/766-98bd1540b448b2b9.js\",\"974\",\"static/chunks/app/page-b0a112a1deee7e7b.js\"],\"default\"]\n14:I[5768,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"static/chunks/497-8f454888f232b3fa.js\",\"663\",\"static/chunks/663-bf703af64886d2e2.js\",\"766\",\"static/chunks/766-98bd1540b448b2b9.js\",\"974\",\"static/chunks/app/page-b0a112a1deee7e7b.js\"],\"default\"]\n15:I[9665,[],\"OutletBoundary\"]\n18:I[9665,[],\"ViewportBoundary\"]\n1a:I[9665,[],\"MetadataBoundary\"]\n1c:I[6614,[],\"\"]\n:HL[\"/_next/static/media/a34f9d1faa5f3315-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/730b9168ceaa3868.css\",\"style\"]\n:HL[\"/_next/static/css/b3cbcd051438d1d5.css\",\"style\"]\nd:T8fc,"])</script><script>self.__next_f.push([1,"\n## Overview\n\nI recently built my personal portfolio website over two days, focusing on keeping the process straightforward and efficient. Rather than overcomplicating the project, I aimed to create a clear, maintainable site that represents my work accurately.\n\n## Tech Stack and Workflow\n\n- **Frontend Hosting:** [AWS Amplify](https://aws.amazon.com/amplify/)\n- **Domain Management:** [AWS Route 53](https://aws.amazon.com/route53/)\n- **Email (Contact Form \u0026 Newsletter):** [Resend](https://resend.com/)\n- **UI Design \u0026 Component Styling:** [v0.dev](https://v0.dev/) + [Shadcn UI](https://ui.shadcn.dev/)\n- **CSS Framework:** [Tailwind CSS](https://tailwindcss.com/)\n- **Framework:** [Next.js (App Router)](https://nextjs.org/)\n\n### Key Features\n\n- Fully responsive design\n- Blog and Projects that are easily editable\n- Markdown files converted to HTML for blog and project content to avoid repetitive HTML/CSS work\n- Animated bird flying across the top page\n- Smooth parallax backgrounds and scroll effects\n- Contact form and newsletter signup integrated with Resend\n- Clean and simple UI, composed with v0.dev and Shadcn components\n- Custom domain set up through AWS Route 53\n\n## Development Breakdown\n\n- **Day 1:**\n  - Defined the UI layout and page structure\n  - Adjusted and finalized the UI using v0.dev and Shadcn components\n  - Set up TailwindCSS and basic styling\n\n- **Day 2:**\n  - Deployed the frontend to AWS Amplify\n  - Linked the contact form and newsletter features to Resend\n  - Configured a custom domain using AWS Route 53\n  - Finalized minor styling adjustments and tested responsiveness\n\nThe two-day development timeline was manageable because of a straightforward workflow and familiarity with the tools used. Even with some additional refinements, the project could easily be completed within three days.\n\n## Reflections\n\nThis project demonstrates my ability to:\n\n- Build a complete and maintainable site within a short time frame\n- Focus on clarity and simplicity in both design and development\n- Integrate external services like Resend smoothly\n- Handle domain setup, project deployment, and site operation independently\n\nIf you're thinking about creating your own portfolio and would like some help, feel free to reach out. I'd be happy to discuss and support your project.\n"])</script><script>self.__next_f.push([1,"e:T9cc,"])</script><script>self.__next_f.push([1,"\n# Learning Singapore’s Birds by Ear: A Look at the SingBirds Call Quiz\n\n## Overview\n\nSingBirds Call Quiz is an interactive web application that challenges players to identify bird species by their songs. The game is centered around birds found in **Singapore**, making it both a fun and educational experience.\n\nPlayers view a **spectrogram** of a bird call and listen to the audio recording before choosing the correct bird species from multiple-choice options. After submitting an answer, they can view detailed information and a photo of the bird.\n\n---\n\n## Features\n\n- 🎧 **Bird Call Audio**: Listen to real bird recordings.\n- 📈 **Spectrogram Display**: Visualize bird calls using spectrograms.\n- ❓ **Multiple-Choice Questions**: Pick the correct species from a list of options.\n- 📝 **Detailed Feedback**:\n  - See which birds you identified correctly or incorrectly.\n  - Access bird information via Wikipedia API after answering.\n  - View bird images dynamically pulled from Wikipedia.\n- 🌎 **Hotspot and Country Selection**: Select specific countries (currently only Singapore) and birding hotspots.\n- 🎚️ **Adjustable Quiz Settings**: Set the number of questions.\n- 📊 **Quiz Result Summary**: Review your score, accuracy, and species performance.\n\n---\n\n## Tech Stack\n\n### Frontend\n- [React](https://react.dev/)\n- [Tailwind CSS](https://tailwindcss.com/) for styling\n\n### Backend\n- [Django](https://www.djangoproject.com/) with Django REST Framework\n- Custom APIs serving species lists, hotspot data, and bird observation records\n\n### Audio Processing\n- [Librosa](https://librosa.org/) for audio analysis\n- [Matplotlib](https://matplotlib.org/) for spectrogram generation\n\n---\n\n## Data Sources\n\n- **eBird API**:\n  - Retrieves Singapore hotspots\n  - Gets bird species observed at hotspots over the past 30 days (snapshot taken in October)\n\n- **Xeno-Canto API**:\n  - Provides bird song recordings\n  - Filters recordings with **Quality A** and durations between **0–30 seconds**\n\n- **Wikipedia API**:\n  - Fetches species descriptions and images dynamically\n\n---\n\n## App Flow\n\n1. Player selects a country (currently only Singapore) and a hotspot.\n2. App retrieves a list of birds based on recent observations (snapshot taken in Oct 2024).\n3. Spectrogram and audio are displayed.\n4. Player submits an answer.\n5. App shows feedback, Wikipedia information, and bird photo.\n6. After the quiz, a final score and breakdown are shown.\n\n\n\nMade with ❤️ for bird lovers around the world.\n\n\n"])</script><script>self.__next_f.push([1,"10:T32f0,"])</script><script>self.__next_f.push([1,"\n\n## Introduction\n\nThis report synthesizes the current literature on training bird sound classification models in data-sparse regional contexts with an emphasis on Singapore or similar Southeast Asian biodiversity hotspots. Overall, the reviewed literature indicates that while many studies develop robust machine learning frameworks using deep convolutional neural networks (CNNs), transfer learning, and semi-supervised techniques for bird sound classification, only a subset of these works explicitly focus on or have been evaluated using Singapore-specific soundscape recordings.\n\n## 1. General Frameworks and Methods in Data-Sparse Contexts\n\nA number of recent studies address the common challenges inherent in bioacoustic monitoring when labeled audio data are scarce. Researchers have proposed solutions that leverage transfer learning from large global datasets, employ data augmentation techniques, and utilize weak or semi-supervised learning approaches to overcome the limited availability of high-quality regional audio samples. For example, Bellafkir et al. (2023) describe a CNN-based approach that uses data augmentation methods such as the addition of background noise and selective mixup to mitigate class imbalances that naturally arise in long-tail distributions. Their methodology—developed originally for challenging soundscapes that include overlapping environmental noises and weak labels—is broadly applicable to scenarios with limited training data, such as those encountered in Southeast Asian urban and forest environments.\n\nDeep transfer learning has been widely adopted to address the data limitation problem. Das et al. (2023) review various CNN architectures, including ResNet, Inception-v3, VGG, MobileNet, DenseNet, and EfficientNet, and detail how pre-trained networks (often on large-scale image or audio datasets) can be fine-tuned on much smaller regional datasets. These approaches considerably reduce the need for large quantities of labeled examples and decrease the training time while improving accuracy. Although the reviewed literature does not always include explicit evaluations using Singapore-specific data, the underlying methodologies show promise for adaptation to any data-sparse, biodiversity-rich region.\n\nIn addition to transfer learning, several groups have explored semi-supervised and weakly supervised approaches. For instance, Caprioli's (2022) work on semi-supervised classification using the FixMatch algorithm demonstrates that even with as few as 11 labeled samples per class, significant accuracy improvements can be attained compared to purely supervised baselines. These techniques are particularly relevant in contexts where field-collected labeled audio is extremely limited, such as in remote or urban ecosystems.\n\n## 2. Challenges in Contexts Like Singapore\n\nMany studies echo similar challenges in limited regional training data, especially when the targeted species are either rare or difficult to record. Common issues include:\n\n- **Limited Availability of High-Quality Labeled Audio Data.** In the field, particularly in highly diverse tropical settings like Singapore, obtaining long-duration recordings with high signal-to-noise ratios is challenging. Critically endangered or resident species often have very sparse recordings, and collector efforts are constrained by practical limitations as well as the fine-grained differences in acoustic patterns (Bellafkir et al., 2023).\n\n- **High Acoustic Similarity Among Coexisting Species.** The coexistence of many species within a small geographical area results in considerable overlap in acoustic signals. This situation demands models that can differentiate subtle variations in call structure and temporal vocalization patterns, which in turn requires inventive signal processing and advanced network architectures capable of capturing both spectral and temporal features (Das et al., 2023).\n\n- **Environmental Noise and Overlapping Vocalizations.** Urban and forest settings in Southeast Asia, including Singapore, are characterized by background noises from both natural and anthropogenic sources. This not only complicates the audio signal but also increases the chance of false positives. Several studies address these problems through sophisticated post-processing techniques, such as class-wise threshold calibrations and confidence penalization for overly common species (Bellafkir et al., 2023).\n\n## 3. Efforts Focused on Singaporean Soundscapes\n\nWhen it comes to directly addressing the Singapore context, there is clear evidence of published work that has explicitly targeted Singapore's unique acoustic environment. Notably, Hexeberg et al. (2025) propose a semi-supervised classification approach for bird vocalizations that is explicitly tested using recordings from Singapore. Their work involves acoustic recordings from local sites—including the Singapore Botanic Gardens—collected over extended periods. This study demonstrates the feasibility of detecting species with overlapping vocalizations and noisy backgrounds in an urban tropical environment by achieving reasonable precision on classes even when trained on very few labeled samples. In further experiments, their classifier is shown to reflect natural diurnal and nocturnal behavioral patterns and to manage site-specific variations effectively. Such results provide strong validation that semi-supervised approaches can be adapted successfully to manage the synthesis of regional data in Singapore.\n\nAdditionally, while Bellafkir et al. (2023) do not explicitly test their model on Singapore data, they note that the efficiency of their pipeline in handling noisy, imbalanced, and weakly labeled datasets makes it well-suited for deployment in tropical urban and forest settings such as Singapore. Thus, although not every study targets Singapore directly, many proposed frameworks are clearly applicable to similar contexts in Southeast Asia.\n\nAnother indirect contribution comes from studies that have been conducted in neighboring regions—such as the SiulMalaya dataset for Malaysia—which similarly face challenges of high species diversity and background noise in lowland forests (Jamil et al., 2023). While the SiulMalaya dataset is specific to Malaysia, the underlying machine learning approaches can offer valuable insights for adapting models to the Singaporean context, given the ecological and acoustic similarities among tropical Southeast Asian habitats.\n\n## 4. Mitigation Strategies in Data-Sparse Settings\n\nSeveral strategies are recommended to address data scarcity in regional contexts such as Singapore:\n\n- **Transfer Learning and Region-Specific Fine-Tuning.** Numerous studies recommend using globally trained models and then fine-tuning them on localized, limited datasets. The use of pre-trained backbones such as EfficientNet (Ansar et al., 2024) and ResNet (Zhong et al., 2021) has been demonstrated to be beneficial when adapting to rare or underrepresented bird sounds. Although many works do not explicitly mention Singapore, the strategies described can be directly applied by incorporating local recording data during the fine-tuning stage.\n\n- **Semi-Supervised and Weakly-Supervised Learning.** In environments where obtaining numerous labels is impractical, semi-supervised approaches that combine small amounts of labeled data with large volumes of unlabeled data provide a promising avenue. Hexeberg et al.'s (2025) work on semi-supervised classification in Singapore demonstrates that even with minimal labeled data, reasonable performance levels can be attained. Similarly, Caprioli's (2022) study on the FixMatch algorithm shows further improvements when pseudo-labels are generated from unlabeled recordings.\n\n- **Data Augmentation and Synthetic Data Generation.** To supplement sparse datasets, augmentation methods such as time stretching, pitch shifting, and mixup are frequently applied. Bellafkir et al. (2023) incorporate several augmentation techniques designed to simulate the presence of background noise and overcome class imbalances. These practices are crucial in developing models that remain robust against the acoustic variability typical of urban and forested soundscapes in Singapore.\n\n## 5. Gaps in the Current Literature\n\nWhile several frameworks have been successfully applied in data-sparse contexts throughout Southeast Asia, there remains a relative paucity of models that have been exclusively trained and validated on Singapore-specific data. Das et al. (2023) note that many deep transfer learning-based studies rely on datasets sourced from global repositories such as Xeno-canto and BirdCLEF, and that there is no explicit reference to Singaporean bird audio recordings within these published efforts. This observation highlights a meaningful gap in the literature: the need for dedicated Singapore-specific datasets and models that account for the unique acoustic challenges, species assemblages, and environmental characteristics within Singapore. Future work in this area could benefit from developing comprehensive local datasets, combining the strengths of both supervised and unsupervised methods, and leveraging metadata (e.g., spatial-temporal information) that might further differentiate the subtle acoustic nuances among local species.\n\n## 6. Conclusion\n\nIn summary, while there is a substantial body of literature that presents methodologies for training bird sound classification models in data-sparse contexts, only select studies have directly tackled the Singapore setting. The work of Hexeberg et al. (2025) clearly demonstrates that a semi-supervised classification approach using Singapore-specific recordings is feasible even in the presence of noise, overlapping calls, and limited labels. Other frameworks developed by Bellafkir et al. (2023) and those based on deep transfer learning by Das et al. (2023) offer methods that are inherently adaptable to Singapore; however, they often rely on data not collected specifically from Singapore. The collective literature emphasizes the importance of harnessing advanced signal processing, ensemble learning, and fine-tuning strategies to address key challenges such as high species diversity, overlapping acoustic signals, and environmental noise. Although Singapore-specific efforts exist and show promising results, there remains a notable gap in published research dedicated solely to Singaporean bird song classification systems. Addressing this gap through continued development of localized data repositories and the adaptation of semi-supervised and transfer learning methods will enhance the accuracy and usability of these systems for biodiversity monitoring in tropical urban and forest contexts.\n\nThis review confirms that, indeed, there is published research concerning Singapore's bird sound classification – most notably the contributions by Hexeberg et al. (2025) – while many global models described in the literature provide methodologies that can be further extended and fine-tuned using local Singapore data. Continued efforts in integrating local recordings with established global models will ultimately lead to more accurate and region-sensitive bioacoustic monitoring systems in Southeast Asia.\n\n## References\n\nAnsar, W., Chatterjee, A., Goswami, S., \u0026 Chakrabarti, A. (2024). An efficientnet-based ensemble for bird-call recognition with enhanced noise reduction. *SN Computer Science, 5*, 265. https://doi.org/10.1007/s42979-023-02591-6\n\nBellafkir, H., Vogelbacher, M., Schneider, D., Kizik, V., Mühling, M., \u0026 Freisleben, B. (2023). Bird species recognition in soundscapes with self-supervised pre-training. *Communications in Computer and Information Science*, 60-74. https://doi.org/10.1007/978-3-031-46338-9_5\n\nCaprioli, E. (2022). *A semi-supervised approach to bird song classification* [Master's thesis, Norwegian University of Science and Technology]. NTNU Open. https://hdl.handle.net/11250/3093609\n\nDas, N., Padhy, N., Dey, N., Bhattacharya, S., \u0026 Tavares, J. M. R. S. (2023). Deep transfer learning-based automated identification of bird song. *International Journal of Interactive Multimedia and Artificial Intelligence, 8*, 33. https://doi.org/10.9781/ijimai.2023.01.003\n\nHexeberg, S., Chitre, M., Hoffmann‐Kuhnt, M., \u0026 Low, B. W. (2025). Semi-supervised classification of bird vocalizations. *ArXiv*. https://doi.org/10.48550/arxiv.2502.13440\n\nJamil, N., Norali, A. N., Ramli, M. I., Shah, A. K. M. K., \u0026 Mamat, I. (2023). Siulmalaya: an annotated bird audio dataset of malaysia lowland forest birds for passive acoustic monitoring. *Bulletin of Electrical Engineering and Informatics, 12*, 2269-2281. https://doi.org/10.11591/beei.v12i4.5243\n\nZhong, M., Taylor, R., Bates, N., Christey, D., Basnet, H., Flippin, J., Palkovitz, S., Dodhia, R., \u0026 Ferres, J. L. (2021). Acoustic detection of regionally rare bird species through deep convolutional neural networks. *Ecological Informatics, 64*, 101333. https://doi.org/10.1016/j.ecoinf.2021.101333"])</script><script>self.__next_f.push([1,"11:T8247,"])</script><script>self.__next_f.push([1,"\n## I. Introduction  \nMonitoring avian biodiversity in regions such as Singapore and other Southeast Asian biodiversity hotspots is a fundamental yet challenging task, particularly when relying on acoustic data. Bird sound classification models are critical for passive acoustic monitoring (PAM) as they provide cost‐effective, scalable, and non‐invasive means to assess ecosystem health. However, the development of accurate audio‐based species classifiers is impeded by a paucity of high-quality labeled regional recordings, the occurrence of sensitive and endangered species with restricted datasets, and high species diversity coupled with acoustic similarity among coexisting birds. This literature review investigates machine learning methods applied to train bird sound classification models in data-sparse regional contexts. It places special emphasis on the challenges encountered in regions such as Singapore and explores approaches that mitigate data sparsity by leveraging transfer learning, semi-supervised or weakly supervised techniques, data augmentation, and region-specific fine-tuning of models like BirdNET ([Bellafkir et al., 2023](https://doi.org/10.1007/978-3-031-46338-9_5), [Jamil et al., 2023](https://doi.org/10.11591/beei.v12i4.5243)).\n\n## II. Machine Learning Methods for Bird Sound Classification  \nA variety of machine learning paradigms have been adopted for bird sound classification, with deep learning frameworks emerging as the prevailing approach due to their ability to learn complex, non-linear representations from spectrogram images of audio recordings.\n\n### A. Convolutional Neural Networks (CNNs)  \nDeep convolutional neural networks (CNNs) are among the most widely used architectures for bird sound classification. CNNs have been successfully applied to spectrogram representations, which capture both temporal and frequency domain features of bird calls. The use of CNNs on spectrograms is fueled by their capacity to automatically learn robust features, thus reducing the need for manual feature engineering ([Stowell et al., 2019](https://doi.org/10.1111/2041-210x.13103)). Advanced CNN architectures, including variants such as AlexNet, VGG16, ResNet50, and DenseNet, have been evaluated for their performance on both large-scale and limited regional datasets. For instance, methods leveraging deep CNNs with attention mechanisms, as seen in some of the recent studies, have demonstrated efficacy in fine-grained bird call classification despite the challenges posed by weak labels and environmental noise ([Bellafkir et al., 2023](https://doi.org/10.1007/978-3-031-46338-9_5)).\n\n### B. Transfer Learning from Global Models  \nTransfer learning is a critical strategy to address data scarcity by repurposing feature extractors pre-trained on large datasets (often from domains such as image classification [e.g., the ImageNet dataset]) for bird sound classification tasks. By using transfer learning, models can leverage general acoustic feature representations and effectively adapt to regional datasets with minimal labeled data ([Das et al., 2023](https://doi.org/10.9781/ijimai.2023.01.003)). The BirdNET framework exemplifies this approach by fine-tuning pre-trained CNN models on global bird sound datasets and subsequently adapting them to local recordings, resulting in improved classification accuracy even when training data is limited ([Kahl et al., 2021](https://doi.org/10.1016/j.ecoinf.2021.101236), [Zhong et al., 2021](https://doi.org/10.1016/j.ecoinf.2021.101333)).\n\n### C. Semi-Supervised and Weakly-Supervised Learning  \nIn regions with sparse labeled data, semi-supervised and weakly-supervised learning approaches have emerged as viable alternatives. These techniques utilize a mixture of labeled and abundant unlabeled audio data to create robust classifiers. For example, FixMatch, a semi-supervised learning algorithm, has been applied to bird sound classification by generating pseudo-labels on unlabeled recordings and improving performance when only a small portion of the dataset is annotated ([Caprioli, 2022](#cite-caprioli2022asemisupervisedapproach)). Likewise, methods based on weak supervision leverage incomplete or imprecise labels by incorporating expert knowledge to fine-tune the model and to mitigate the noise and inconsistencies that often arise in crowdsourced audio recordings ([Conde et al., 2021](https://doi.org/10.48550/arxiv.2107.04878)).\n\n### D. Data Augmentation Strategies  \nData augmentation plays a crucial role in combating overfitting and enhancing the generalization capabilities of classifiers trained on limited regional data. Techniques such as time and pitch shifting, spectrogram axis shifting, mixup, and the addition of background noise (including, for instance, external bird audio recordings) have been applied to artificially expand the dataset. These augmentations help simulate variations encountered in real-world recordings, particularly in acoustically complex environments typical of tropical regions ([Ansar et al., 2024](https://doi.org/10.1007/s42979-023-02591-6), [Nshimiyimana, 2024](https://doi.org/10.1007/s11042-023-17959-2)). By generating synthetic variations, data augmentation also alleviates the challenges of class imbalance, which is especially pertinent when rare species are represented by only a few samples ([Das et al., 2023](https://doi.org/10.9781/ijimai.2023.01.003)).\n\n## III. Challenges in Data-Sparse Regional Contexts  \nTraining bird sound classification models in regions such as Singapore presents unique challenges that can be grouped into three main areas: limited availability of high-quality labeled audio data, the sensitive nature of datasets concerning endangered species, and the high acoustic similarity amid diverse species.\n\n### A. Limited Availability of High-Quality Labeled Audio Data  \nOne of the predominant challenges in data-sparse regional contexts is the scarcity of high-quality labeled audio recordings. In many biodiversity hotspots, the production of expert-verified annotated datasets is both time-consuming and resource-intensive. For example, studies like SiulMalaya have addressed these challenges by combining citizen science data with expert annotations, but even then, classification accuracies remain modest due to the limited amount of available training data ([Jamil et al., 2023](https://doi.org/10.11591/beei.v12i4.5243)). Limited datasets force researchers to work with sparse examples, and when these audio recordings are combined with diverse environmental noises, the task of effective bird sound classification becomes significantly more complex.\n\n### B. Sensitive or Endangered Species with Restricted Datasets  \nThe conservation status of many avian species necessitates careful handling of the related acoustic data. Some rare or endangered species appear infrequently in recordings, resulting in severely imbalanced datasets. This imbalance not only raises issues of overfitting during model training but also increases the likelihood of false negatives, which could impede conservation efforts. As many of these species are of high ecological significance, models must be carefully designed to maintain sensitivity to rare calls while avoiding misclassifications caused by background noise or overlapping vocalizations ([Zhong et al., 2021](https://doi.org/10.1016/j.ecoinf.2021.101333), [Caprioli, 2022](#cite-caprioli2022asemisupervisedapproach)).\n\n### C. High Species Diversity and Acoustic Similarity  \nSoutheast Asian ecosystems, particularly in regions like Singapore, are characterized by high species diversity. This diversity is accompanied by significant acoustic similarity among species, especially those that co-occur in dense habitats such as urban parks and rainforests. The overlap in frequency ranges and temporal patterns among bird calls increases the complexity of classification, necessitating models capable of discerning subtle differences. In these contexts, even minor variations introduced by different recording conditions or the presence of ambient noise can lead to misclassifications, further complicating the task ([Bellafkir et al., 2023](https://doi.org/10.1007/978-3-031-46338-9_5), [Tang et al., 2024](https://doi.org/10.1371/journal.pone.0297988)).\n\n## IV. Approaches to Mitigate Data Sparsity  \nResearchers have developed several strategies to mitigate the inherent difficulties in training accurate bird sound classifiers using limited regional data. These strategies leverage advancements in transfer learning, semi-supervised learning, and data augmentation, among other techniques.\n\n### A. Transfer Learning from Global to Regional Domains  \nThe concept of transfer learning involves the adaptation of models pre-trained on large global datasets to the specific conditions found in a regional context. For bird sound classification, large-scale datasets such as those collected via Xeno-canto or the BirdCLEF challenges serve as a robust foundation from which models can learn general acoustic features. These models can then be fine-tuned with available regional data to capture local environmental and species-specific characteristics. For instance, models such as ResNet50 and EfficientNet have been successfully adapted from global datasets to recognize calls in regionally limited contexts ([Das et al., 2023](https://doi.org/10.9781/ijimai.2023.01.003), [Kahl et al., 2021](https://doi.org/10.1016/j.ecoinf.2021.101236)). BirdNET further exemplifies this strategy by employing region-specific fine-tuning that incorporates quality-based loss weighting and threshold calibration to adapt to the local acoustic domain, thereby improving performance on limited and noisy regional audio samples ([Bellafkir et al., 2023](https://doi.org/10.1007/978-3-031-46338-9_5), [Ansar et al., 2024](https://doi.org/10.1007/s42979-023-02591-6)).\n\n### B. Semi-Supervised, Self-Supervised, and Weakly-Supervised Learning Techniques  \nWhen labeled data are sparse, semi-supervised and weakly-supervised methods allow models to leverage the abundance of unlabeled recordings. Semi-supervised algorithms, such as FixMatch, combine a small, high-quality labeled dataset with a larger pool of unlabeled data by generating pseudo-labels and filtering them using confidence thresholds. This approach has been shown to improve accuracy by effectively expanding the training data without incurring the high costs of manual annotation ([Caprioli, 2022](#cite-caprioli2022asemisupervisedapproach)). Similarly, weakly supervised techniques address label noise by working with incomplete or imprecise labels, adapting to the inherent uncertainty in field-collected recordings, and thereby enabling the training of robust classifiers even with limited labeled data ([Conde et al., 2021](https://doi.org/10.48550/arxiv.2107.04878)).\n\n### C. Data Augmentation and Synthetic Data Generation  \nData augmentation strategies serve as another cornerstone for mitigating the challenges associated with limited regional datasets. By applying transformations such as time stretching, pitch shifting, adding synthetic background noise, and mixup methods, researchers can artificially expand the available dataset and introduce variability that helps the model generalize better to unseen data. Such techniques have been particularly effective in overcoming issues related to environmental variability and class imbalance ([Ansar et al., 2024](https://doi.org/10.1007/s42979-023-02591-6), [Nshimiyimana, 2024](https://doi.org/10.1007/s11042-023-17959-2)). Additionally, the generation of synthetic data through proxy species or simulated audio environments can further enrich training datasets, thereby compensating for the scarcity of examples for rare or sensitive species.\n\n### D. Region-Specific Fine-Tuning of Pre-Trained Models  \nAn effective way to bridge the gap between global models and local conditions is through region-specific fine-tuning. Models that are initially pre-trained on large and diverse datasets capture general acoustic patterns that are then refined using limited regional recordings. Fine-tuning of models such as BirdNET on localized data allows the classifier to account for differences in environmental acoustics, species behavior, and recording equipment. This process not only improves recognition accuracy but also helps in adjusting model sensitivity to variations that are specific to regions like Singapore ([Zhong et al., 2021](https://doi.org/10.1016/j.ecoinf.2021.101333), [Rajan \u0026 Noumida, 2021](https://doi.org/10.1109/iccisc52257.2021.9484858)).\n\n### E. Integration of Meta Information and Proxy Modalities  \nIn addition to traditional acoustic features derived from spectrograms, incorporating auxiliary meta information—such as textual descriptions of bird calls, ecological traits, and life-history data—can further bolster classification performance. Meta-information allows models to contextualize audio data by leveraging additional cues about species' habitats, morphology, and behavior. Recent studies have shown that concatenating AVONET features (including ecological and morphological traits) with life-history characteristics can improve zero-shot audio classification performance, thereby enhancing the model's ability to generalize from global datasets to region-specific contexts ([Gebhard et al., 2024](https://doi.org/10.1109/icassp48485.2024.10445807)).\n\n## V. Synthesis of Approaches for Southeast Asia and Singapore  \nThe convergence of methods such as transfer learning, semi-supervised techniques, and robust data augmentation offers a promising path forward for developing accurate bird sound classifiers in data-sparse regional contexts, particularly in Southeast Asia and Singapore. In practice, these methods can be integrated into a comprehensive pipeline that begins with the acquisition and pre-processing of raw audio data followed by the application of advanced CNN architectures. Pre-processing steps include cropping long recordings into manageable time windows, converting the audio into Mel spectrograms, and applying noise reduction filters tailored to the local acoustic environment ([Bellafkir et al., 2023](https://doi.org/10.1007/978-3-031-46338-9_5), [LeBien et al., 2020](https://doi.org/10.1016/j.ecoinf.2020.101113)).\n\nInitial training on large-scale global datasets enables the model to learn generic acoustic features, which are then transferred to the target domain through fine-tuning with regional audio. This stage is critical in regions such as Singapore where environmental conditions, recording equipment quality, and species vocalizations vary significantly from those found in global datasets ([Das et al., 2023](https://doi.org/10.9781/ijimai.2023.01.003), [Kahl et al., 2021](https://doi.org/10.1016/j.ecoinf.2021.101236)). Following the transfer learning stage, semi-supervised and weakly supervised techniques further expand the training dataset through pseudo-labeling of unlabeled recordings, thereby mitigating the effects of scarce annotated data ([Caprioli, 2022](#cite-caprioli2022asemisupervisedapproach), [Conde et al., 2021](https://doi.org/10.48550/arxiv.2107.04878)).\n\nData augmentation remains an integral enhancement in such pipelines, where techniques ranging from simple time-pitch shifting to complex mixup training are utilized to simulate the variability of natural soundscapes. This is particularly important for training robust classifiers capable of distinguishing between acoustically similar species in biodiverse regions ([Ansar et al., 2024](https://doi.org/10.1007/s42979-023-02591-6), [Nshimiyimana, 2024](https://doi.org/10.1007/s11042-023-17959-2)). Moreover, integrating meta-information associated with the birds, such as ecological attributes and life-history traits, can offer an additional layer of context. This approach is crucial when distinguishing between species with high acoustic similarity, ensuring that the classifier accounts for subtle yet biologically meaningful differences ([Gebhard et al., 2024](https://doi.org/10.1109/icassp48485.2024.10445807)).\n\nIn scenarios where the acoustic recordings include data for rare or endangered species, methods such as proxy species generation and the use of synthetic data can further compensate for the limited number of examples available. Not only do these methods enrich the overall dataset, but they also help in training models that are resilient to the variances in call frequency and intensity found among rare species ([Rajan \u0026 Noumida, 2021](https://doi.org/10.1109/iccisc52257.2021.9484858), [Stowell et al., 2019](https://doi.org/10.1111/2041-210x.13103)).\n\n## VI. Discussion and Future Directions  \nDrawing from the diverse approaches detailed in the reviewed literature, it is evident that the combination of modern deep learning techniques with domain-specific adaptations is key to overcoming data sparsity in bird sound classification tasks. The effectiveness of transfer learning is particularly notable—pre-trained models that are fine-tuned with regional data can bridge the gap between heterogeneous audio domains and provide high classification accuracy despite sparse labeled examples ([Das et al., 2023](https://doi.org/10.9781/ijimai.2023.01.003), [Kahl et al., 2021](https://doi.org/10.1016/j.ecoinf.2021.101236)).\n\nMoving forward, several research directions appear promising. One area of active research is the further development of self-supervised learning algorithms that do not require any annotated labels at all during pre-training. With the advent of self-supervised models in other domains, there is potential to harness large volumes of unlabeled audio recordings from biodiversity hotspots, thus reducing reliance on manual annotations ([Caprioli, 2022](#cite-caprioli2022asemisupervisedapproach)). Researchers might also explore architectures that combine CNN and recurrent neural network (RNN) layers to capture both spectral and temporal features more effectively, as these hybrid models have demonstrated improved performance in recognizing overlapping and sequential bird vocalizations ([Stowell et al., 2019](https://doi.org/10.1111/2041-210x.13103)).\n\nFurthermore, the integration of active learning strategies—where the model selectively queries the most uncertain examples for expert labeling—could help optimize the annotation process in data-sparse environments. Active learning has the potential to greatly reduce the labeling effort required, ensuring that only the most impactful data points are annotated, thereby enhancing overall classifier performance ([Clink et al., 2024](https://doi.org/10.1101/2024.08.17.608420)).\n\nRegion-specific studies are essential to validate and refine these methodologies. In the context of Singapore, a densely populated and ecologically complex urban setting, factors such as urban noise, seasonal changes, and the influence of diverse habitat types must be considered. Future work should involve collecting more localized audio data and implementing fine-tuning steps that emphasize these unique acoustic properties while incorporating community-driven citizen science initiatives to build larger, high-quality annotated datasets ([Jamil et al., 2023](https://doi.org/10.11591/beei.v12i4.5243), [LeBien et al., 2020](https://doi.org/10.1016/j.ecoinf.2020.101113)).\n\nAnother promising avenue is the use of ensemble modeling techniques, where multiple classifiers are combined to improve overall accuracy and robustness. Ensemble approaches have been shown to reduce the variance inherent in single-model predictions, thereby yielding more reliable results in challenging acoustic environments ([Henkel \u0026 Singer, 2021](https://doi.org/10.48550/arxiv.2107.07728), [Rajan \u0026 Noumida, 2021](https://doi.org/10.1109/iccisc52257.2021.9484858)).\n\nIntegration of multi-modal data also presents a strong opportunity. For instance, coupling audio data with environmental and visual metadata could provide additional discriminative power. This multi-modal approach is particularly relevant for habitats where bird calls are acoustically similar. By aligning acoustic signals with spatial, temporal, and ecological metadata, classifiers could achieve improved differentiation among species that are otherwise challenging to distinguish based solely on audio ([Gebhard et al., 2024](https://doi.org/10.1109/icassp48485.2024.10445807), [Tang et al., 2024](https://doi.org/10.1371/journal.pone.0297988)).\n\n## VII. Recommendations for Implementation in Singapore and Similar Southeast Asian Contexts  \nBased on the literature reviewed, researchers and practitioners working in data-sparse regional contexts such as Singapore should consider the following recommendations for developing robust bird sound classification systems:\n\n### 1. Leverage Global Transfer Learning:  \n   Initiate model training on extensive, established global bird acoustic databases and fine-tune on a curated subset of local recordings. Pre-trained CNN architectures, especially those adapted into frameworks such as BirdNET, should form the backbone of regional classifiers due to their demonstrated ability to generalize across diverse acoustic domains ([Das et al., 2023](https://doi.org/10.9781/ijimai.2023.01.003), [Kahl et al., 2021](https://doi.org/10.1016/j.ecoinf.2021.101236)).\n\n### 2. Incorporate Semi- and Weakly-Supervised Techniques:  \n   Exploit the abundance of unlabeled audio data available via passive acoustic monitoring networks by adopting semi-supervised learning methods such as FixMatch or alternative weakly supervised algorithms. This approach will help bridge the gap caused by limited expert annotations, enabling models to learn from both high-quality labeled recordings and a larger pool of unlabeled data ([Caprioli, 2022](#cite-caprioli2022asemisupervisedapproach), [Conde et al., 2021](https://doi.org/10.48550/arxiv.2107.04878)).\n\n### 3. Employ Robust Data Augmentation:  \n   Use a comprehensive suite of data augmentation techniques to enhance training dataset diversity. Time and pitch shifting, noise injection, and mixup training can simulate various recording conditions encountered in urban and forested areas in Singapore, improving the model's ability to generalize under varying environmental conditions ([Ansar et al., 2024](https://doi.org/10.1007/s42979-023-02591-6), [Nshimiyimana, 2024](https://doi.org/10.1007/s11042-023-17959-2)).\n\n### 4. Focus on Region-Specific Fine-Tuning:  \n   After transfer learning from global datasets, dedicate resources to fine-tuning the model on locally collected data. Incorporate region-specific acoustic characteristics and environmental factors into the training process. This step is crucial in ensuring that the model remains sensitive to the subtle inter-species variations and local noise conditions characteristic of Southeast Asian soundscapes ([Zhong et al., 2021](https://doi.org/10.1016/j.ecoinf.2021.101333), [Rajan \u0026 Noumida, 2021](https://doi.org/10.1109/iccisc52257.2021.9484858)).\n\n### 5. Integrate Meta Information and Multi-Modal Data:  \n   Supplement audio features with relevant meta information such as species morphological traits, ecological data, and temporal recording metadata. This integrative approach can help disambiguate calls from species with high acoustic similarity, enabling more precise classification in biodiversity-rich regions where multiple, overlapping signals are common ([Gebhard et al., 2024](https://doi.org/10.1109/icassp48485.2024.10445807), [Tang et al., 2024](https://doi.org/10.1371/journal.pone.0297988)).\n\n### 6. Utilize Ensemble Approaches and Active Learning:  \n   Combine multiple machine learning models to form an ensemble that reduces variance and enhances the robustness of predictions. Additionally, implement active learning strategies to prioritize labeling of the most ambiguous recordings, thereby optimizing the use of limited expert resources ([Henkel \u0026 Singer, 2021](https://doi.org/10.48550/arxiv.2107.07728), [Clink et al., 2024](https://doi.org/10.1101/2024.08.17.608420)).\n\n## VIII. Conclusion  \nThe literature reviewed herein clearly demonstrates that modern deep learning techniques—augmented by transfer learning, semi-supervised methods, and robust data augmentation—offer a promising solution to the problem of training bird sound classification models in data-sparse regional contexts. Regions like Singapore, characterized by high biodiversity and complex, acoustically noisy environments, present unique challenges that can be effectively addressed through the integration of global models with region-specific fine-tuning, active learning, and meta-data fusion. While the scarcity of high-quality labeled data remains a significant obstacle, the combination of these approaches promises to enhance monitoring capabilities, support conservation efforts for endangered species, and ultimately contribute to a more informed understanding of Southeast Asian biodiversity ([Bellafkir et al., 2023](https://doi.org/10.1007/978-3-031-46338-9_5), [Das et al., 2023](https://doi.org/10.9781/ijimai.2023.01.003), [Jamil et al., 2023](https://doi.org/10.11591/beei.v12i4.5243), [Stowell et al., 2019](https://doi.org/10.1111/2041-210x.13103)).\n\nFuture research is encouraged to expand on these methodologies by incorporating emerging techniques such as self-supervised representation learning and the further exploration of multi-modal data fusion. Such advancements are essential for the evolution of PAM systems that can overcome the inherent limitations of data-sparse environments. Researchers should also prioritize the creation of large-scale, expert-annotated regional datasets—potentially through collaborations that combine citizen science efforts with standardized recording protocols—to further refine model performance and generalization in tropical urban and forest settings ([LeBien et al., 2020](https://doi.org/10.1016/j.ecoinf.2020.101113), [Tang et al., 2024](https://doi.org/10.1371/journal.pone.0297988), [Zhong et al., 2021](https://doi.org/10.1016/j.ecoinf.2021.101333)).\n\nIn summary, the integration of transfer learning, semi-supervised learning, data augmentation, and region-specific fine-tuning constitutes the cornerstone of effective bird sound classification in Southeast Asia. This approach not only addresses the challenge of limited annotated data but also facilitates the recognition of highly similar and overlapping bird calls in complex soundscapes, ultimately contributing to robust and scalable biodiversity monitoring systems. Such systems are essential for informing conservation strategies and ensuring that even rare or endangered species are appropriately monitored, thereby supporting the broader goals of ecosystem management and biodiversity conservation ([Das et al., 2023](https://doi.org/10.9781/ijimai.2023.01.003), [Kahl et al., 2021](https://doi.org/10.1016/j.ecoinf.2021.101236), [Rajan \u0026 Noumida, 2021](https://doi.org/10.1109/iccisc52257.2021.9484858)).\n\nBy adopting and further refining these strategies, practitioners in regions like Singapore can transform sparse audio datasets into valuable, actionable insights that drive the next generation of environmental monitoring and conservation efforts. This body of work, drawing on advances from both global and region-specific studies, offers a comprehensive framework for overcoming data limitations and achieving high-performance bird sound classification in challenging ecological contexts.\n\nIn conclusion, accurate bird sound classification in data-sparse regional environments is not only feasible but also essential for effective biodiversity monitoring. The successful integration of advanced machine learning techniques with contextual domain knowledge ensures that even in regions with limited data, reliable and scalable models can be developed. Researchers must continue to explore and refine these integrated approaches, as they hold the key to bridging the gap between global methodologies and local environmental challenges, ultimately fostering a deeper understanding of the rich and diverse avifauna in Southeast Asia ([Bellafkir et al., 2023](https://doi.org/10.1007/978-3-031-46338-9_5), [Ansar et al., 2024](https://doi.org/10.1007/s42979-023-02591-6), [Stowell et al., 2019](https://doi.org/10.1111/2041-210x.13103)).\n\nThrough collaborative efforts that combine expertise in machine learning, ecology, and local field studies, the future of bird sound classification in biodiversity hotspots is bright. Such collaborative initiatives will pave the way for more effective deployment of PAM systems, ensuring that limited regional datasets are leveraged to their fullest potential, thereby contributing significantly to conservation and ecological research in dynamic and complex urban and natural environments.\n\n## References\n\n1. Ansar, W., Chatterjee, A., Goswami, S., \u0026 Chakrabarti, A. (2024). [An EfficientNet-based ensemble for bird-call recognition with enhanced noise reduction](https://doi.org/10.1007/s42979-023-02591-6). *SN Computer Science, 5*, 265. (4 citations, peer-reviewed)\n\n2. Bellafkir, H., Vogelbacher, M., Schneider, D., Kizik, V., Mühling, M., \u0026 Freisleben, B. (2023). [Bird species recognition in soundscapes with self-supervised pre-training](https://doi.org/10.1007/978-3-031-46338-9_5). *Communications in Computer and Information Science*, 60-74. (3 citations, peer-reviewed)\n\n3. Caprioli, E. (2022). [A semi-supervised approach to bird song classification](https://hdl.handle.net/11250/3093609). Master's thesis, Norwegian University of Science and Technology (NTNU). Advisor: Downing, K.\n\n4. Clink, D. J., Cross-Jaya, H., Kim, J., Ahmad, A. H., Hong, M., Sala, R., Birot, H., Agger, C., Vu, T. T., Thi, H. N., Chi, T. N., \u0026 Klinck, H. (2024). [Benchmarking automated detection and classification approaches for monitoring of endangered species: a case study on gibbons from Cambodia](https://doi.org/10.1101/2024.08.17.608420). *bioRxiv*. (0 citations)\n\n5. Conde, M. V., Shubham, K., \u0026 Agnihotri, P. (2021). [Weakly-supervised classification and detection of bird sounds in the wild: a BirdCLEF 2021 solution](https://doi.org/10.48550/arxiv.2107.04878). *ArXiv*.\n\n6. Das, N., Padhy, N., Dey, N., Bhattacharya, S., \u0026 Tavares, J. M. R. S. (2023). [Deep transfer learning-based automated identification of bird song](https://doi.org/10.9781/ijimai.2023.01.003). *International Journal of Interactive Multimedia and Artificial Intelligence, 8*, 33. (3 citations)\n\n7. Gebhard, A., Triantafyllopoulos, A., Bez, T., Christ, L., Kathan, A., \u0026 Schuller, B. W. (2024). [Exploring meta information for audio-based zero-shot bird classification](https://doi.org/10.1109/icassp48485.2024.10445807). *ICASSP 2024 - IEEE International Conference on Acoustics, Speech and Signal Processing*, 1211-1215. (6 citations)\n\n8. Henkel, C., \u0026 Singer, P. (2021). [Recognizing bird species in diverse soundscapes under weak supervision](https://doi.org/10.48550/arxiv.2107.07728). *ArXiv*.\n\n9. Jamil, N., Norali, A. N., Ramli, M. I., Shah, A. K. M. K., \u0026 Mamat, I. (2023). [Siulmalaya: an annotated bird audio dataset of Malaysia lowland forest birds for passive acoustic monitoring](https://doi.org/10.11591/beei.v12i4.5243). *Bulletin of Electrical Engineering and Informatics, 12*, 2269-2281. (3 citations)\n\n10. Kahl, S., Wood, C. M., Eibl, M., \u0026 Klinck, H. (2021). [BirdNET: A deep learning solution for avian diversity monitoring](https://doi.org/10.1016/j.ecoinf.2021.101236). *Ecological Informatics, 61*, 101236. (648 citations, peer-reviewed)\n\n11. LeBien, J., Zhong, M., Campos-Cerqueira, M., Velev, J. P., Dodhia, R., Ferres, J. L., \u0026 Aide, T. M. (2020). [A pipeline for identification of bird and frog species in tropical soundscape recordings using a convolutional neural network](https://doi.org/10.1016/j.ecoinf.2020.101113). *Ecological Informatics, 59*, 101113. (161 citations, peer-reviewed)\n\n12. Nshimiyimana, A. (2024). [Acoustic data augmentation for small passive acoustic monitoring datasets](https://doi.org/10.1007/s11042-023-17959-2). *Multimedia Tools and Applications, 83*, 63397-63415. (3 citations, peer-reviewed)\n\n13. Rajan, R., \u0026 Noumida, A. (2021). [Multi-label bird species classification using transfer learning](https://doi.org/10.1109/iccisc52257.2021.9484858). *International Conference on Communication, Control and Information Sciences (ICCISc)*, 1-5. (23 citations)\n\n14. Stowell, D., Wood, M. D., Pamuła, H., Stylianou, Y., \u0026 Glotin, H. (2019). [Automatic acoustic detection of birds through deep learning: the first bird audio detection challenge](https://doi.org/10.1111/2041-210x.13103). *Methods in Ecology and Evolution, 10*, 368-380. (420 citations, highest quality peer-reviewed journal)\n\n15. Tang, Y., Liu, C., \u0026 Yuan, X. (2024). [Recognition of bird species with birdsong records using machine learning methods](https://doi.org/10.1371/journal.pone.0297988). *PLOS ONE, 19*, e0297988. (4 citations, peer-reviewed)\n\n16. Zhong, M., Taylor, R., Bates, N., Christey, D., Basnet, H., Flippin, J., Palkovitz, S., Dodhia, R., \u0026 Ferres, J. L. (2021). [Acoustic detection of regionally rare bird species through deep convolutional neural networks](https://doi.org/10.1016/j.ecoinf.2021.101333). *Ecological Informatics, 64*, 101333. (49 citations, peer-reviewed)\n\n\n\n\n\n\n\n"])</script><script>self.__next_f.push([1,"12:T2f69,"])</script><script>self.__next_f.push([1,"\n### [BirdNET](https://birdnet.cornell.edu/)\n\n#### Overview\n\nBirdNET is a free AI-powered bird sound identification tool developed by the Cornell Lab of Ornithology and Chemnitz University. It is very user-friendly – no birding experience is needed; users simply record a bird’s song on their smartphone and let the app identify it. BirdNET can recognize over 3,000 bird species by sound (as of 2022) and is continually expanding its coverage. The app is available for iOS and Android devices, and there’s also a web demo for uploading audio clips.\n\n#### Ease of Use\nBirdNET’s interface is simple: just tap Record to capture a bird call, then tap Analyze. The recording is uploaded to BirdNET’s servers, which quickly return the most likely species matches. Results include a probability score (e.g. “Highly Certain” or “Uncertain”) for each identification. Because analysis happens in the cloud, an internet connection is required during use. Overall, the app lowers the barrier for birding by ear – even total beginners can get an ID by just using their phone’s microphone. (Note: BirdNET is a citizen-science tool; each confirmed recording can be submitted to researchers for conservation studies.)\n\n\n#### Access\n\n Download BirdNET from the App Store or Google Play (free). Open the app and allow microphone and location access. When you hear a bird, press the record button and wait a few seconds to capture the sound. Next, select the portion of the spectrogram (visual representation of the sound) that contains the bird call and tap the Identify button. The app will display the top species matches for the sound, along with confidence ratings. You can tap a result to learn more about the bird. It’s that easy – BirdNET handles the complex audio analysis using its trained neural network on the back-end.\n\n### [Merlin](https://merlin.allaboutbirds.org/)\n\n#### Overview\n\nMerlin Bird ID is a popular bird identification app from Cornell Lab, geared toward the general public. Initially known for photo and sighting IDs, Merlin added a Sound ID feature in 2021 that can recognize hundreds of species by their songs and calls. It’s also free and available on iOS and Android. Merlin is designed to be extremely easy to use, making birding by ear feel “like magic” for beginners.\n\n#### Ease of Use\n\nUsing Merlin’s Sound ID is straightforward and works offline once you’ve downloaded a region-specific bird pack. As the app listens through your phone’s microphone, it uses AI to analyze the sound and in real time displays the names and photos of species it hears. The live feedback means you can watch a list of bird names appear as each bird sings, which is very intuitive. Merlin can even detect multiple birds at once and highlight each species when it sings, helping users parse bird choruses. This real-time, continuous identification makes Merlin a great learning tool – users can tap on an identified bird to see more info (calls, range, ID tips), or replay the recording to reinforce recognition.\n\n#### Access \u0026 Usage\n\nInstall Merlin Bird ID from your app store (free). Upon first use, you’ll download a bird pack for your region (which includes sounds for the local species). To use Sound ID, open the app and tap Sound ID. Simply hold up your phone and tap the microphone icon to start listening. Merlin will continuously display any species it recognizes. You can tap a species name in the list to pinpoint where in the recording that bird sang, play back that segment, and read about the species. Merlin’s sound identification works without a data connection (ideal for remote areas) since the recognition runs on your device.\n\n### [Song Sleuth](https://www.sibleyguides.com/product/song-sleuth/) \n\n#### Overview\n\nSong Sleuth is a smartphone app (iOS; a past Android version was planned) that was one of the first bird song recognition tools for North America. Developed by Wildlife Acoustics with birding expert David Sibley, the app can identify about 200 common bird species by their songs. It’s a paid app (around $10) and is geared toward bird enthusiasts who want more than a quick ID – it also provides illustrations, species info, and a spectrogram visualization for learning purposes.\n\n#### Ease of Use\n\nSong Sleuth’s interface is a bit more technical but rewarding. When you open the app, it continuously displays a live spectrogram (graph of sound frequencies) of all sounds around you. To ID a bird, you press record when the bird sings; the app automatically captures the song (even a few seconds prior to tapping, using a buffer) and highlights it on the spectrogram. Then tap the Identify button, and Song Sleuth will analyze the sound and present a short list of possible species matches. In tests, it often provides the correct species or at least gets you “in the ballpark” of similar sounding birds. This semi-manual process (selecting the target call on the spectrogram) means there is a small learning curve, but it was praised as an elegant system for users to visualize and identify songs. The app also saves your recordings and identifications for later review or study.\n\n#### Access \u0026 Usage\n\nSong Sleuth is available on the Apple App Store (no longer officially supported, but still downloadable). After installing, launch the app and choose your region if prompted (to filter species). When birding, open Song Sleuth and watch the scrolling spectrogram. When you hear a bird, tap Record to capture the sound (then Stop). The app will mark the suspected bird song automatically; if needed, adjust the selection on the spectrogram. Next, tap Analyze to get identification results. You’ll see a list of likely species (often with the top 2–3 candidates) and you can compare your recording to example songs in the app’s library. Remember that Song Sleuth doesn’t require internet – all processing is on-device. Note: The developer is no longer updating Song Sleuth (as of 2021), so its species list is fixed at 200 and future OS compatibility isn’t guaranteed.\n\n### [ChirpOMatic UK](https://www.chirpomatic.com/) \n\n#### Overview \n\nChirpOMatic is another widely available birdsong recognition app, originally developed for the U.K. and now with a North American version as well. It’s a paid mobile app (available on iOS, and on Android in some regions) focused on simplicity for casual users. ChirpOMatic contains a library of common bird sounds and uses AI to match your recording to these sounds. Its species coverage is more regional (e.g. a UK app version for British birds, and a separate app for North America).\n\n#### Ease of Use\n\nChirpOMatic’s workflow is very straightforward: you open the app and manually start a recording when you hear a bird. (It doesn’t continuously buffer audio like some others, so you do have to anticipate the bird’s song.) After recording a clip of the bird, you tap Identify, and the app will list the likely species. In reviewer tests, ChirpOMatic’s accuracy was comparable to Song Sleuth for clear recordings. The app includes a built-in library of bird calls and even lets you save and submit your recordings to help improve the AI model over time. This community feedback approach means the app can get better with user contributions. The interface is user-friendly, with minimal buttons – essentially record, stop, and results – making it approachable for beginners.\n\n#### Access \u0026 Usage\n\nDownload ChirpOMatic UK or ChirpOMatic USA from the app store (they are separate apps tailored to regional birds). In the field, launch the app and press the Record button as soon as the bird starts singing. Try to get a few seconds of clear audio, then press Stop. Tap the Identify (or “Analyze”) option, and the app will compare your clip to its bird sound database. It will show the best match or a short list of possible species. You can tap a result to confirm by listening to a reference recording of that species. The app doesn’t require an internet connection for identification, which is handy in remote areas. Finally, if you want, use the option to Submit the recording – this uploads your clip for the developers to potentially use in refining their AI (making ChirpOMatic a kind of citizen-science helper as well).\n\n### [BirdNET-Analyzer](https://github.com/kahst/BirdNET-Analyzer)\n\n#### Overview\n\nBirdNET-Analyzer is a research-oriented tool based on the BirdNET AI, intended for bulk analysis of audio recordings rather than real-time identification. While the BirdNET app serves the public, BirdNET-Analyzer is designed for scientists and conservationists dealing with large datasets (for example, months of autonomous recorder files). It’s essentially the BirdNET neural network packaged with a user-friendly interface for desktop use. The software is free and open-source, available on GitHub for Windows, Linux, and MacOS. (BirdNET’s functionality has also been integrated into Cornell’s flagship bioacoustics program, Raven Pro, for researchers who use that software.)\n\n#### Ease of Use\n\nFor a research tool, BirdNET-Analyzer is considered easy to install and run. It provides a simple GUI on Windows – you don’t need advanced programming skills to use it. Researchers can load a folder of audio files, choose settings like location/time filters or confidence thresholds, and then let the software automatically identify bird calls in those recordings. The output typically includes timestamps of detections and the predicted species names with confidence scores. This significantly speeds up analysis of passive acoustic monitoring data, where manual review would be too time-consuming. Because it’s the same core AI as the app, it can detect a wide range of species. In fact, the latest BirdNET-Analyzer release can recognize over 6,500 species of birds worldwide, making it suitable for global research projects. (It has even begun to include other animal sounds like certain frogs and primates in recent updates.)\n\n#### Access \u0026 Usage\n\nBirdNET-Analyzer is distributed via GitHub as a free download. To use it, one typically downloads the program (or Python package) and a pre-trained model file. The tool can be run with a graphical interface (on Windows) or via command-line for scripting (useful for large-scale processing on a server). Basic usage involves selecting an input directory of audio files and an output directory, then clicking Run. The software will process each file, scanning for bird sounds and logging any identified species with timing and confidence. You can refine results by adjusting the confidence threshold (to balance between missing faint calls and filtering out false positives). The documentation provides guidelines for these settings, and since it’s open-source, advanced users can even retrain or tweak the model for specific research needs. \n\n#### Research Orientation \n\nThis tool is mainly used in scientific studies and conservation projects, not by casual birders. It has been used to validate acoustic monitoring of cryptic bird species in forests, and generally aims to empower researchers to leverage AI for biodiversity surveys. (For example, a biologist could deploy autonomous recorders in the field, then use BirdNET-Analyzer to rapidly identify which bird species vocalized in the recordings each day.) Its strength lies in processing large audio datasets efficiently and consistently – a clear win for bioacoustics research.\n\n### References\n\n1. Cornell Lab of Ornithology – AI-powered BirdNET app makes citizen science easier (June 28, 2022)\n2. BirdNET official website – About BirdNET and download links (BirdNET app usage)\n3. Cornell Lab of Ornithology – What bird is singing? Merlin Bird ID app offers instant answers (June 23, 2021)\n4. BirdWatching Magazine – The best birdsong apps (2021/2022)\n5. Audubon Magazine – Testing Out Song Sleuth, a New App That Identifies Birds by Their Calls (Feb 21, 2017)\n6. Granjon et al. (2023) – Hearing the Unseen: AudioMoth and BirdNET as a Cheap and Easy Method for Monitoring Cryptic Bird Species, Sensors (MDPI) (BirdNET-Analyzer details)\n\n"])</script><script>self.__next_f.push([1,"13:T11f3,"])</script><script>self.__next_f.push([1,"\n### Introduction\n\nBird vocalizations serve as a cornerstone of avian ecology, playing indispensable roles in behaviors critical for survival and reproduction. However, increasing urbanization has introduced significant anthropogenic noise pollution, severely impeding acoustic communication. This report conducts a comparative analysis of bird vocalization characteristics in urban and forest habitats and explores avian strategies to mitigate noise masking.\n\n### Bird Vocalizations in Forest Habitats\n\nIn natural forest environments, bird songs evolve to optimize transmission through dense vegetation. Forests favor lower frequency, tonal vocalizations, and the acoustic environment is shaped by vegetation density, habitat openness, and wildlife presence, guiding song efficiency.\n\n### Bird Vocalizations in Urban Habitats\n\nUrban environments drastically alter bird vocalizations:\n\n- **Song Complexity:** Urban song thrushes show greater syllable repertoire and repetition; song sparrows show no significant difference.\n- **Frequency Shift:** Urban species like blackbirds and great tits sing at higher frequencies.\n- **Temporal Characteristics:** Urban birds sing longer, faster songs; some shift singing times earlier.\n- **Amplitude Modulation:** Urban birds, like blackbirds, sing louder; white-crowned sparrows sang softer during the pandemic.\n- **Syllable Usage:** Urban song thrushes favor more twitter syllables over whistle syllables.\n\n### Strategies for Mitigating Anthropogenic Noise\n\nBirds employ:\n\n- **Active Adjustments:** Immediate song modifications (e.g., Lombard effect, changing singing times).\n- **Evolutionary Adaptations:** Genetic shifts favoring high-frequency song production.\n- **Behavioral Adaptations:** Strategic perch selection and timing adjustments.\n\n### Other Influencing Factors\n\nUrban factors influencing vocalization:\n\n- **Population Density:** Drives longer, faster songs.\n- **Urban Structure:** Reflects and distorts sound differently from forests.\n- **Morphology:** Vocal tract structures constrain sound production.\n\n### Ecological and Behavioral Implications\n\n- **Mate Choice:** Song changes influence mate selection and reproductive isolation.\n- **Territorial Defense:** Noise masks aggressive signals, impairing territory defense.\n- **Fitness Costs:** Higher frequencies may reduce vocal performance, impacting fitness.\n\n### Theoretical Context: Acoustic Adaptation Hypothesis (AAH)\n\nAAH posits habitat-specific signal evolution. Urban bird songs partially align with AAH predictions but other pressures like social interactions also play significant roles.\n\n### Conservation Implications\n\nRecommendations for conservation:\n\n- Reduce urban noise.\n- Create quieter green spaces.\n- Improve habitat connectivity.\n- Use bioacoustic monitoring for assessment.\n\nFuture research should prioritize the long-term ecological and evolutionary consequences of urbanization on bird vocalizations.\n\n### Conclusion\n\nUrbanization leads to significant alterations in bird vocalizations, mainly due to anthropogenic noise. Birds adapt through frequency shifts, complexity adjustments, and timing modifications, affecting mate choice, territorial defense, and overall fitness. Conservation strategies must aim to mitigate noise and protect avian biodiversity.\n\n### Summary of Observed Changes in Bird Song Characteristics in Urban vs. Forest Habitats\n\n| Species | Song Characteristic | Urban vs. Forest | Potential Driving Factor(s) |\n|:-------|:---------------------|:----------------|:----------------------------|\n| Song Thrush | Syllable Repertoire Size | Greater | Anthropogenic Noise |\n| Song Thrush | Syllable Sequence Repetition | More Frequent | Anthropogenic Noise |\n| Song Thrush | Whistle Syllable Proportion | Smaller | Anthropogenic Noise |\n| Song Thrush | Twitter Syllable Proportion | Higher | Anthropogenic Noise |\n| Song Thrush | Whistle Syllable Frequency | Higher (Min \u0026 Peak) | Anthropogenic Noise |\n| Blackbird | Minimum Frequency | Higher | Anthropogenic Noise |\n| Blackbird | Song Amplitude | Higher | Higher Frequency Usage (Correlation) |\n| Northern Cardinal | Minimum Frequency | Higher | Anthropogenic Noise |\n| Northern Cardinal | Song Length | Longer | Higher Population Density, Territorial Interactions |\n| Northern Cardinal | Song Rate | Faster | Higher Population Density, Territorial Interactions |\n| Great Tit | Minimum Frequency | Higher | Anthropogenic Noise |\n| Song Sparrow | Repertoire Size | No Significant Difference |  - |\n| White-crowned Sparrow | Song Amplitude | Softer (During Pandemic) | Reduced Anthropogenic Noise |\n\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"nli5VSm0dNMiC8p1OoAct\",\"p\":\"\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/730b9168ceaa3868.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/b3cbcd051438d1d5.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"className\":\"__className_d65c78\",\"children\":[\"$\",\"$L2\",null,{\"attribute\":\"class\",\"defaultTheme\":\"light\",\"enableSystem\":false,\"disableTransitionOnChange\":true,\"children\":[[\"$\",\"$L3\",null,{}],[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"footer\",null,{\"className\":\"py-8 border-t\",\"children\":[\"$\",\"div\",null,{\"className\":\"container mx-auto px-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-col md:flex-row justify-between items-center gap-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-col items-center md:items-start\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-2 mb-2\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-8 h-8 rounded-full overflow-hidden mr-2\",\"children\":[\"$\",\"$L6\",null,{\"src\":\"/pitta-gpt.png\",\"alt\":\"SingBirds Logo\",\"width\":32,\"height\":32,\"className\":\"w-full h-full object-cover\"}]}],[\"$\",\"h3\",null,{\"className\":\"text-xl font-bold gradient-text\",\"children\":\"SingBirds\"}]]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground text-center md:text-left\",\"children\":\"I Code Birds.\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex gap-4\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://github.com/fairy-pitta\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-muted-foreground hover:text-sky-500 transition-colors\",\"aria-label\":\"GitHub\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-github h-6 w-6\",\"children\":[[\"$\",\"path\",\"tonef\",{\"d\":\"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4\"}],[\"$\",\"path\",\"9comsn\",{\"d\":\"M9 18c-4.51 2-5-2-7-2\"}],\"$undefined\"]}]}]}]]}],[\"$\",\"div\",null,{\"className\":\"border-t mt-6 pt-6 flex flex-col md:flex-row justify-between items-center gap-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":[\"© \",2025,\" SingBirds. All rights reserved.\"]}],[\"$\",\"div\",null,{\"className\":\"flex gap-6 text-sm\",\"children\":[[\"$\",\"a\",null,{\"href\":\"/privacy\",\"className\":\"text-muted-foreground hover:text-sky-500 transition-colors\",\"children\":\"Privacy Policy\"}],[\"$\",\"a\",null,{\"href\":\"/terms\",\"className\":\"text-muted-foreground hover:text-sky-500 transition-colors\",\"children\":\"Terms of Service\"}]]}]]}]]}]}]]}]}]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"main\",null,{\"className\":\"relative overflow-hidden\",\"children\":[[\"$\",\"$L7\",null,{}],[\"$\",\"$L8\",null,{}],[\"$\",\"$L9\",null,{}],[\"$\",\"section\",null,{\"id\":\"about\",\"className\":\"snap-section min-h-screen relative\",\"children\":[\"$\",\"$La\",null,{}]}],[\"$\",\"section\",null,{\"id\":\"skills\",\"className\":\"snap-section min-h-screen relative\",\"children\":[\"$\",\"$Lb\",null,{}]}],[\"$\",\"section\",null,{\"id\":\"projects\",\"className\":\"snap-section min-h-screen relative\",\"children\":[\"$\",\"$Lc\",null,{\"projects\":[{\"slug\":\"Portfolio\",\"frontmatter\":{\"title\":\"Building My Portfolio in Two Days\",\"description\":\"I built my personal portfolio website in two days, focusing on a clear and maintainable design without unnecessary complexity.\",\"date\":\"22 Apr, 2025\",\"coverImage\":\"/projects/Portfolio/portfolio_main.png\",\"tags\":[\"Web App\",\"Next.js\",\"AWS\",\"Amplify\",\"v0\"],\"liveUrl\":\"https://singbirds.net\",\"githubUrl\":\"https://github.com/fairy-pitta/singbirds-portfolio\",\"gallery\":[\"/projects/Portfolio/portfolio_project.png\",\"/projects/Portfolio/portfolio_skills.png\",\"/projects/Portfolio/portfolio_mobile.png\"]},\"content\":\"$d\"},{\"slug\":\"SGBirdCall\",\"frontmatter\":{\"title\":\"Learning Singapore’s Birds by Ear: A Look at the SingBirds Call Quiz\",\"description\":\"An interactive quiz web app to test out your bird call knowledge\",\"date\":\"Oct 15, 2024\",\"coverImage\":\"/projects/callquiz/CallQuiz_main.png\",\"tags\":[\"React\",\"Django\",\"Birds\"],\"liveUrl\":\"https://quiz.singbirds.net/\",\"githubUrl\":\"https://github.com/fairy-pitta/Singbirds-frontend\",\"gallery\":[\"/projects/callquiz/CallQuiz_correct.png\",\"/projects/callquiz/CallQuiz_home.png\",\"/projects/callquiz/CallQuiz_result.png\",\"/projects/callquiz/CallQuiz_top.png\"]},\"content\":\"$e\"}]}]}],[\"$\",\"section\",null,{\"id\":\"blog\",\"className\":\"snap-section min-h-screen relative\",\"children\":[\"$\",\"$Lf\",null,{\"posts\":[{\"slug\":\"bird-sound-classification-in-singapore\",\"frontmatter\":{\"title\":\"Singapore - Challenges and Progress in Bioacoustics\",\"date\":\"May 6, 2025\",\"excerpt\":\"A quick look at the bioacoustics challenges in Singapore\",\"coverImage\":\"/blogs/bird_call_singapore.png\",\"readTime\":\"10 min read\",\"tags\":[\"Deep Research\",\"bioacoustics\",\"Singapore\"]},\"content\":\"$10\"},{\"slug\":\"bird-sound-classification-in-data-sparse-regional-context\",\"frontmatter\":{\"title\":\"Approaches Bioacoutics via Data\",\"date\":\"May 5, 2025\",\"excerpt\":\"Bird Sound Classification in Data-Sparse Regional Contexts: Literature Review\",\"coverImage\":\"/blogs/bird_call_illustration.png\",\"readTime\":\"20 min read\",\"tags\":[\"Deep Research\",\"bioacoustics\",\"data analysis\"]},\"content\":\"$11\"},{\"slug\":\"tools-for-bird-acoustic-monitoring\",\"frontmatter\":{\"title\":\"New Technologies for Bird Acoustic Monitoring\",\"date\":\"April 27, 2025\",\"excerpt\":\"Bird monitoring tools are transforming conservation across Southeast Asia\",\"coverImage\":\"/blogs/ecological-model-on-screen.png\",\"readTime\":\"10 min read\",\"tags\":[\"Deep Research\",\"bioacoustics\"]},\"content\":\"$12\"},{\"slug\":\"change-in-bird-vocalization\",\"frontmatter\":{\"title\":\"Changes in Bird Vocalization in City vs. Forest\",\"date\":\"April 26, 2025\",\"excerpt\":\"A quick look at the changes in bird vocalizations between urban and forest\",\"coverImage\":\"/blogs/bird_calling.JPG\",\"readTime\":\"10 min read\",\"tags\":[\"Deep Research\",\"bioacoustics\"]},\"content\":\"$13\"}]}]}],[\"$\",\"section\",null,{\"id\":\"contact\",\"className\":\"snap-section min-h-screen relative\",\"children\":[\"$\",\"$L14\",null,{}]}]]}],\"$undefined\",null,[\"$\",\"$L15\",null,{\"children\":[\"$L16\",\"$L17\",null]}]]}],{},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"20wJPx5A997egG6T9E1wZ\",{\"children\":[[\"$\",\"$L18\",null,{\"children\":\"$L19\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$L1a\",null,{\"children\":\"$L1b\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$1c\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"19:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n16:null\n"])</script><script>self.__next_f.push([1,"17:null\n1b:[[\"$\",\"title\",\"0\",{\"children\":\"SingBirds | Environmental Tech Developer\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Portfolio of SingBirds - Environmental Technologist and Developer\"}],[\"$\",\"meta\",\"2\",{\"name\":\"application-name\",\"content\":\"SingBirds\"}],[\"$\",\"meta\",\"3\",{\"name\":\"author\",\"content\":\"SingBirds\"}],[\"$\",\"meta\",\"4\",{\"name\":\"generator\",\"content\":\"v0.dev\"}],[\"$\",\"link\",\"5\",{\"rel\":\"shortcut icon\",\"href\":\"/favicon.ico\"}],[\"$\",\"link\",\"6\",{\"rel\":\"icon\",\"href\":\"/fairy-pitta.png\"}],[\"$\",\"link\",\"7\",{\"rel\":\"apple-touch-icon\",\"href\":\"/apple-icon.png\"}]]\n"])</script></body></html>