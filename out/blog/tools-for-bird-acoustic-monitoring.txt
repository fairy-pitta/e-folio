1:"$Sreact.fragment"
2:I[9304,["874","static/chunks/874-564943c90346e675.js","497","static/chunks/497-8f454888f232b3fa.js","766","static/chunks/766-98bd1540b448b2b9.js","177","static/chunks/app/layout-83c85cf5db64605f.js"],"ThemeProvider"]
3:I[9578,["874","static/chunks/874-564943c90346e675.js","497","static/chunks/497-8f454888f232b3fa.js","766","static/chunks/766-98bd1540b448b2b9.js","177","static/chunks/app/layout-83c85cf5db64605f.js"],"default"]
4:I[7555,[],""]
5:I[1295,[],""]
6:I[3063,["874","static/chunks/874-564943c90346e675.js","497","static/chunks/497-8f454888f232b3fa.js","766","static/chunks/766-98bd1540b448b2b9.js","177","static/chunks/app/layout-83c85cf5db64605f.js"],"Image"]
8:I[9665,[],"OutletBoundary"]
b:I[9665,[],"ViewportBoundary"]
d:I[9665,[],"MetadataBoundary"]
f:I[6614,[],""]
:HL["/_next/static/media/a34f9d1faa5f3315-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/730b9168ceaa3868.css","style"]
:HL["/_next/static/css/b3cbcd051438d1d5.css","style"]
0:{"P":null,"b":"nli5VSm0dNMiC8p1OoAct","p":"","c":["","blog","tools-for-bird-acoustic-monitoring"],"i":false,"f":[[["",{"children":["blog",{"children":[["slug","tools-for-bird-acoustic-monitoring","d"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/730b9168ceaa3868.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/b3cbcd051438d1d5.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":["$","body",null,{"className":"__className_d65c78","children":["$","$L2",null,{"attribute":"class","defaultTheme":"light","enableSystem":false,"disableTransitionOnChange":true,"children":[["$","$L3",null,{}],["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}],["$","footer",null,{"className":"py-8 border-t","children":["$","div",null,{"className":"container mx-auto px-4","children":[["$","div",null,{"className":"flex flex-col md:flex-row justify-between items-center gap-6","children":[["$","div",null,{"className":"flex flex-col items-center md:items-start","children":[["$","div",null,{"className":"flex items-center gap-2 mb-2","children":[["$","div",null,{"className":"w-8 h-8 rounded-full overflow-hidden mr-2","children":["$","$L6",null,{"src":"/pitta-gpt.png","alt":"SingBirds Logo","width":32,"height":32,"className":"w-full h-full object-cover"}]}],["$","h3",null,{"className":"text-xl font-bold gradient-text","children":"SingBirds"}]]}],["$","p",null,{"className":"text-sm text-muted-foreground text-center md:text-left","children":"I Code Birds."}]]}],["$","div",null,{"className":"flex gap-4","children":["$","a",null,{"href":"https://github.com/fairy-pitta","target":"_blank","rel":"noopener noreferrer","className":"text-muted-foreground hover:text-sky-500 transition-colors","aria-label":"GitHub","children":["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-github h-6 w-6","children":[["$","path","tonef",{"d":"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"}],["$","path","9comsn",{"d":"M9 18c-4.51 2-5-2-7-2"}],"$undefined"]}]}]}]]}],["$","div",null,{"className":"border-t mt-6 pt-6 flex flex-col md:flex-row justify-between items-center gap-4","children":[["$","div",null,{"className":"text-sm text-muted-foreground","children":["© ",2025," SingBirds. All rights reserved."]}],["$","div",null,{"className":"flex gap-6 text-sm","children":[["$","a",null,{"href":"/privacy","className":"text-muted-foreground hover:text-sky-500 transition-colors","children":"Privacy Policy"}],["$","a",null,{"href":"/terms","className":"text-muted-foreground hover:text-sky-500 transition-colors","children":"Terms of Service"}]]}]]}]]}]}]]}]}]}]]}],{"children":["blog",["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["slug","tools-for-bird-acoustic-monitoring","d"],["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L7","$undefined",null,["$","$L8",null,{"children":["$L9","$La",null]}]]}],{},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","bnoLgSZTd08XDsrjCrLie",{"children":[["$","$Lb",null,{"children":"$Lc"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],["$","$Ld",null,{"children":"$Le"}]]}],false]],"m":"$undefined","G":["$f","$undefined"],"s":false,"S":true}
c:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
9:null
10:I[3440,["874","static/chunks/874-564943c90346e675.js","497","static/chunks/497-8f454888f232b3fa.js","663","static/chunks/663-bf703af64886d2e2.js","953","static/chunks/app/blog/%5Bslug%5D/page-fbcb4166984d1917.js"],"default"]
11:I[6874,["874","static/chunks/874-564943c90346e675.js","497","static/chunks/497-8f454888f232b3fa.js","663","static/chunks/663-bf703af64886d2e2.js","953","static/chunks/app/blog/%5Bslug%5D/page-fbcb4166984d1917.js"],""]
13:I[2776,["874","static/chunks/874-564943c90346e675.js","497","static/chunks/497-8f454888f232b3fa.js","663","static/chunks/663-bf703af64886d2e2.js","953","static/chunks/app/blog/%5Bslug%5D/page-fbcb4166984d1917.js"],"default"]
12:T3082,<h3><a href="https://birdnet.cornell.edu/">BirdNET</a></h3>
<h4>Overview</h4>
<p>BirdNET is a free AI-powered bird sound identification tool developed by the Cornell Lab of Ornithology and Chemnitz University. It is very user-friendly – no birding experience is needed; users simply record a bird’s song on their smartphone and let the app identify it. BirdNET can recognize over 3,000 bird species by sound (as of 2022) and is continually expanding its coverage. The app is available for iOS and Android devices, and there’s also a web demo for uploading audio clips.</p>
<h4>Ease of Use</h4>
<p>BirdNET’s interface is simple: just tap Record to capture a bird call, then tap Analyze. The recording is uploaded to BirdNET’s servers, which quickly return the most likely species matches. Results include a probability score (e.g. “Highly Certain” or “Uncertain”) for each identification. Because analysis happens in the cloud, an internet connection is required during use. Overall, the app lowers the barrier for birding by ear – even total beginners can get an ID by just using their phone’s microphone. (Note: BirdNET is a citizen-science tool; each confirmed recording can be submitted to researchers for conservation studies.)</p>
<h4>Access</h4>
<p>Download BirdNET from the App Store or Google Play (free). Open the app and allow microphone and location access. When you hear a bird, press the record button and wait a few seconds to capture the sound. Next, select the portion of the spectrogram (visual representation of the sound) that contains the bird call and tap the Identify button. The app will display the top species matches for the sound, along with confidence ratings. You can tap a result to learn more about the bird. It’s that easy – BirdNET handles the complex audio analysis using its trained neural network on the back-end.</p>
<h3><a href="https://merlin.allaboutbirds.org/">Merlin</a></h3>
<h4>Overview</h4>
<p>Merlin Bird ID is a popular bird identification app from Cornell Lab, geared toward the general public. Initially known for photo and sighting IDs, Merlin added a Sound ID feature in 2021 that can recognize hundreds of species by their songs and calls. It’s also free and available on iOS and Android. Merlin is designed to be extremely easy to use, making birding by ear feel “like magic” for beginners.</p>
<h4>Ease of Use</h4>
<p>Using Merlin’s Sound ID is straightforward and works offline once you’ve downloaded a region-specific bird pack. As the app listens through your phone’s microphone, it uses AI to analyze the sound and in real time displays the names and photos of species it hears. The live feedback means you can watch a list of bird names appear as each bird sings, which is very intuitive. Merlin can even detect multiple birds at once and highlight each species when it sings, helping users parse bird choruses. This real-time, continuous identification makes Merlin a great learning tool – users can tap on an identified bird to see more info (calls, range, ID tips), or replay the recording to reinforce recognition.</p>
<h4>Access &#x26; Usage</h4>
<p>Install Merlin Bird ID from your app store (free). Upon first use, you’ll download a bird pack for your region (which includes sounds for the local species). To use Sound ID, open the app and tap Sound ID. Simply hold up your phone and tap the microphone icon to start listening. Merlin will continuously display any species it recognizes. You can tap a species name in the list to pinpoint where in the recording that bird sang, play back that segment, and read about the species. Merlin’s sound identification works without a data connection (ideal for remote areas) since the recognition runs on your device.</p>
<h3><a href="https://www.sibleyguides.com/product/song-sleuth/">Song Sleuth</a></h3>
<h4>Overview</h4>
<p>Song Sleuth is a smartphone app (iOS; a past Android version was planned) that was one of the first bird song recognition tools for North America. Developed by Wildlife Acoustics with birding expert David Sibley, the app can identify about 200 common bird species by their songs. It’s a paid app (around $10) and is geared toward bird enthusiasts who want more than a quick ID – it also provides illustrations, species info, and a spectrogram visualization for learning purposes.</p>
<h4>Ease of Use</h4>
<p>Song Sleuth’s interface is a bit more technical but rewarding. When you open the app, it continuously displays a live spectrogram (graph of sound frequencies) of all sounds around you. To ID a bird, you press record when the bird sings; the app automatically captures the song (even a few seconds prior to tapping, using a buffer) and highlights it on the spectrogram. Then tap the Identify button, and Song Sleuth will analyze the sound and present a short list of possible species matches. In tests, it often provides the correct species or at least gets you “in the ballpark” of similar sounding birds. This semi-manual process (selecting the target call on the spectrogram) means there is a small learning curve, but it was praised as an elegant system for users to visualize and identify songs. The app also saves your recordings and identifications for later review or study.</p>
<h4>Access &#x26; Usage</h4>
<p>Song Sleuth is available on the Apple App Store (no longer officially supported, but still downloadable). After installing, launch the app and choose your region if prompted (to filter species). When birding, open Song Sleuth and watch the scrolling spectrogram. When you hear a bird, tap Record to capture the sound (then Stop). The app will mark the suspected bird song automatically; if needed, adjust the selection on the spectrogram. Next, tap Analyze to get identification results. You’ll see a list of likely species (often with the top 2–3 candidates) and you can compare your recording to example songs in the app’s library. Remember that Song Sleuth doesn’t require internet – all processing is on-device. Note: The developer is no longer updating Song Sleuth (as of 2021), so its species list is fixed at 200 and future OS compatibility isn’t guaranteed.</p>
<h3><a href="https://www.chirpomatic.com/">ChirpOMatic UK</a></h3>
<h4>Overview</h4>
<p>ChirpOMatic is another widely available birdsong recognition app, originally developed for the U.K. and now with a North American version as well. It’s a paid mobile app (available on iOS, and on Android in some regions) focused on simplicity for casual users. ChirpOMatic contains a library of common bird sounds and uses AI to match your recording to these sounds. Its species coverage is more regional (e.g. a UK app version for British birds, and a separate app for North America).</p>
<h4>Ease of Use</h4>
<p>ChirpOMatic’s workflow is very straightforward: you open the app and manually start a recording when you hear a bird. (It doesn’t continuously buffer audio like some others, so you do have to anticipate the bird’s song.) After recording a clip of the bird, you tap Identify, and the app will list the likely species. In reviewer tests, ChirpOMatic’s accuracy was comparable to Song Sleuth for clear recordings. The app includes a built-in library of bird calls and even lets you save and submit your recordings to help improve the AI model over time. This community feedback approach means the app can get better with user contributions. The interface is user-friendly, with minimal buttons – essentially record, stop, and results – making it approachable for beginners.</p>
<h4>Access &#x26; Usage</h4>
<p>Download ChirpOMatic UK or ChirpOMatic USA from the app store (they are separate apps tailored to regional birds). In the field, launch the app and press the Record button as soon as the bird starts singing. Try to get a few seconds of clear audio, then press Stop. Tap the Identify (or “Analyze”) option, and the app will compare your clip to its bird sound database. It will show the best match or a short list of possible species. You can tap a result to confirm by listening to a reference recording of that species. The app doesn’t require an internet connection for identification, which is handy in remote areas. Finally, if you want, use the option to Submit the recording – this uploads your clip for the developers to potentially use in refining their AI (making ChirpOMatic a kind of citizen-science helper as well).</p>
<h3><a href="https://github.com/kahst/BirdNET-Analyzer">BirdNET-Analyzer</a></h3>
<h4>Overview</h4>
<p>BirdNET-Analyzer is a research-oriented tool based on the BirdNET AI, intended for bulk analysis of audio recordings rather than real-time identification. While the BirdNET app serves the public, BirdNET-Analyzer is designed for scientists and conservationists dealing with large datasets (for example, months of autonomous recorder files). It’s essentially the BirdNET neural network packaged with a user-friendly interface for desktop use. The software is free and open-source, available on GitHub for Windows, Linux, and MacOS. (BirdNET’s functionality has also been integrated into Cornell’s flagship bioacoustics program, Raven Pro, for researchers who use that software.)</p>
<h4>Ease of Use</h4>
<p>For a research tool, BirdNET-Analyzer is considered easy to install and run. It provides a simple GUI on Windows – you don’t need advanced programming skills to use it. Researchers can load a folder of audio files, choose settings like location/time filters or confidence thresholds, and then let the software automatically identify bird calls in those recordings. The output typically includes timestamps of detections and the predicted species names with confidence scores. This significantly speeds up analysis of passive acoustic monitoring data, where manual review would be too time-consuming. Because it’s the same core AI as the app, it can detect a wide range of species. In fact, the latest BirdNET-Analyzer release can recognize over 6,500 species of birds worldwide, making it suitable for global research projects. (It has even begun to include other animal sounds like certain frogs and primates in recent updates.)</p>
<h4>Access &#x26; Usage</h4>
<p>BirdNET-Analyzer is distributed via GitHub as a free download. To use it, one typically downloads the program (or Python package) and a pre-trained model file. The tool can be run with a graphical interface (on Windows) or via command-line for scripting (useful for large-scale processing on a server). Basic usage involves selecting an input directory of audio files and an output directory, then clicking Run. The software will process each file, scanning for bird sounds and logging any identified species with timing and confidence. You can refine results by adjusting the confidence threshold (to balance between missing faint calls and filtering out false positives). The documentation provides guidelines for these settings, and since it’s open-source, advanced users can even retrain or tweak the model for specific research needs.</p>
<h4>Research Orientation</h4>
<p>This tool is mainly used in scientific studies and conservation projects, not by casual birders. It has been used to validate acoustic monitoring of cryptic bird species in forests, and generally aims to empower researchers to leverage AI for biodiversity surveys. (For example, a biologist could deploy autonomous recorders in the field, then use BirdNET-Analyzer to rapidly identify which bird species vocalized in the recordings each day.) Its strength lies in processing large audio datasets efficiently and consistently – a clear win for bioacoustics research.</p>
<h3>References</h3>
<ol>
<li>Cornell Lab of Ornithology – AI-powered BirdNET app makes citizen science easier (June 28, 2022)</li>
<li>BirdNET official website – About BirdNET and download links (BirdNET app usage)</li>
<li>Cornell Lab of Ornithology – What bird is singing? Merlin Bird ID app offers instant answers (June 23, 2021)</li>
<li>BirdWatching Magazine – The best birdsong apps (2021/2022)</li>
<li>Audubon Magazine – Testing Out Song Sleuth, a New App That Identifies Birds by Their Calls (Feb 21, 2017)</li>
<li>Granjon et al. (2023) – Hearing the Unseen: AudioMoth and BirdNET as a Cheap and Easy Method for Monitoring Cryptic Bird Species, Sensors (MDPI) (BirdNET-Analyzer details)</li>
</ol>7:["$","$L10",null,{"children":["$","div",null,{"className":"min-h-screen bg-background","children":["$","div",null,{"className":"pt-14 md:pt-16","children":["$","div",null,{"className":"container mx-auto px-4 py-12","children":["$","div",null,{"className":"max-w-3xl mx-auto","children":[["$","$L11",null,{"href":"/blog","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-arrow-left h-4 w-4 mr-2","children":[["$","path","1l729n",{"d":"m12 19-7-7 7-7"}],["$","path","x3x0zl",{"d":"M19 12H5"}],"$undefined"]}],"Back to Blog"],"className":"inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0 hover:bg-accent hover:text-accent-foreground h-10 px-4 py-2 mb-6","ref":null}],["$","h1",null,{"className":"text-3xl md:text-4xl font-bold mb-4","children":"New Technologies for Bird Acoustic Monitoring"}],["$","div",null,{"className":"flex flex-wrap items-center gap-4 mb-6","children":[["$","span",null,{"className":"flex items-center text-muted-foreground","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-calendar h-4 w-4 mr-1","children":[["$","path","1cmpym",{"d":"M8 2v4"}],["$","path","4m81vk",{"d":"M16 2v4"}],["$","rect","1hopcy",{"width":"18","height":"18","x":"3","y":"4","rx":"2"}],["$","path","8toen8",{"d":"M3 10h18"}],"$undefined"]}],"April 27, 2025"]}],["$","span",null,{"className":"flex items-center text-muted-foreground","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-clock h-4 w-4 mr-1","children":[["$","circle","1mglay",{"cx":"12","cy":"12","r":"10"}],["$","polyline","68esgv",{"points":"12 6 12 12 16 14"}],"$undefined"]}],"10 min read"]}]]}],["$","div",null,{"className":"flex flex-wrap gap-2 mb-8","children":[["$","$L11","Deep Research",{"href":"/blog/tag/deep-research","children":["$","div",null,{"className":"inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground hover:bg-sky-50 cursor-pointer","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-tag h-3 w-3 mr-1","children":[["$","path","vktsd0",{"d":"M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"}],["$","circle","kqv944",{"cx":"7.5","cy":"7.5","r":".5","fill":"currentColor"}],"$undefined"]}],"Deep Research"]}]}],["$","$L11","bioacoustics",{"href":"/blog/tag/bioacoustics","children":["$","div",null,{"className":"inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground hover:bg-sky-50 cursor-pointer","children":[["$","svg",null,{"ref":"$undefined","xmlns":"http://www.w3.org/2000/svg","width":24,"height":24,"viewBox":"0 0 24 24","fill":"none","stroke":"currentColor","strokeWidth":2,"strokeLinecap":"round","strokeLinejoin":"round","className":"lucide lucide-tag h-3 w-3 mr-1","children":[["$","path","vktsd0",{"d":"M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"}],["$","circle","kqv944",{"cx":"7.5","cy":"7.5","r":".5","fill":"currentColor"}],"$undefined"]}],"bioacoustics"]}]}]]}],["$","div",null,{"className":"mb-8","children":["$","img",null,{"src":"/blogs/ecological-model-on-screen.png","alt":"New Technologies for Bird Acoustic Monitoring","className":"w-full rounded-lg"}]}],["$","div",null,{"className":"prose prose-sky prose-img:rounded-xl prose-headings:scroll-mt-8 prose-a:text-sky-600 max-w-none sm:prose-lg","dangerouslySetInnerHTML":{"__html":"$12"}}],["$","div",null,{"className":"my-12","children":["$","$L13",null,{}]}]]}]}]}]}]}]
a:null
e:[["$","title","0",{"children":"New Technologies for Bird Acoustic Monitoring | SingBirds"}],["$","meta","1",{"name":"description","content":"Bird monitoring tools are transforming conservation across Southeast Asia"}],["$","meta","2",{"name":"application-name","content":"SingBirds"}],["$","meta","3",{"name":"author","content":"SingBirds"}],["$","meta","4",{"name":"generator","content":"v0.dev"}],["$","link","5",{"rel":"shortcut icon","href":"/favicon.ico"}],["$","link","6",{"rel":"icon","href":"/fairy-pitta.png"}],["$","link","7",{"rel":"apple-touch-icon","href":"/apple-icon.png"}]]
