<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/a34f9d1faa5f3315-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/blogs/bird_call_singapore.png"/><link rel="stylesheet" href="/_next/static/css/730b9168ceaa3868.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/b3cbcd051438d1d5.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-84be5e7f048f0d69.js"/><script src="/_next/static/chunks/4bd1b696-f767626c8b2c1958.js" async=""></script><script src="/_next/static/chunks/684-44969689c1ecc70e.js" async=""></script><script src="/_next/static/chunks/main-app-44c3966afc00716c.js" async=""></script><script src="/_next/static/chunks/874-564943c90346e675.js" async=""></script><script src="/_next/static/chunks/497-8f454888f232b3fa.js" async=""></script><script src="/_next/static/chunks/766-98bd1540b448b2b9.js" async=""></script><script src="/_next/static/chunks/app/layout-83c85cf5db64605f.js" async=""></script><script src="/_next/static/chunks/663-bf703af64886d2e2.js" async=""></script><script src="/_next/static/chunks/app/blog/%5Bslug%5D/page-fbcb4166984d1917.js" async=""></script><meta name="next-size-adjust" content=""/><title>Singapore - Challenges and Progress in Bioacoustics | SingBirds</title><meta name="description" content="A quick look at the bioacoustics challenges in Singapore"/><meta name="application-name" content="SingBirds"/><meta name="author" content="SingBirds"/><meta name="generator" content="v0.dev"/><link rel="shortcut icon" href="/favicon.ico"/><link rel="icon" href="/fairy-pitta.png"/><link rel="apple-touch-icon" href="/apple-icon.png"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__className_d65c78"><script>((e,t,r,n,o,a,i,l)=>{let u=document.documentElement,s=["light","dark"];function c(t){var r;(Array.isArray(e)?e:[e]).forEach(e=>{let r="class"===e,n=r&&a?o.map(e=>a[e]||e):o;r?(u.classList.remove(...n),u.classList.add(a&&a[t]?a[t]:t)):u.setAttribute(e,t)}),r=t,l&&s.includes(r)&&(u.style.colorScheme=r)}if(n)c(n);else try{let e=localStorage.getItem(t)||r,n=i&&"system"===e?window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light":e;c(n)}catch(e){}})("class","theme","light",null,["light","dark"],null,false,true)</script><nav class="fixed top-0 w-full z-50 transition-all duration-300 bg-background/80 backdrop-blur-md shadow-sm"><div class="container mx-auto px-4 py-4 flex justify-between items-center"><a class="flex items-center gap-2" href="/"><div class="w-8 h-8 rounded-full overflow-hidden mr-2"><img alt="SingBirds Logo" loading="lazy" width="32" height="32" decoding="async" data-nimg="1" class="w-full h-full object-cover" style="color:transparent" src="/pitta-gpt.png"/></div><span class="text-2xl font-bold gradient-text">SingBirds</span></a><div class="flex items-center gap-6"><button class="text-sm font-medium transition-colors text-sky-600 hover:text-sky-800">About</button><button class="text-sm font-medium transition-colors text-sky-600 hover:text-sky-800">Skills</button><a class="text-sm font-medium transition-colors text-sky-600 hover:text-sky-800" href="/projects">Projects</a><a class="text-sm font-medium transition-colors text-sky-800 font-semibold" href="/blog">Blog</a><button class="text-sm font-medium transition-colors text-sky-600 hover:text-sky-800">Contact</button></div></div></nav><div class="min-h-screen bg-background"><div class="pt-14 md:pt-16"><div class="container mx-auto px-4 py-12"><div class="max-w-3xl mx-auto"><a class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 hover:bg-accent hover:text-accent-foreground h-10 px-4 py-2 mb-6" href="/blog"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-arrow-left h-4 w-4 mr-2"><path d="m12 19-7-7 7-7"></path><path d="M19 12H5"></path></svg>Back to Blog</a><h1 class="text-3xl md:text-4xl font-bold mb-4">Singapore - Challenges and Progress in Bioacoustics</h1><div class="flex flex-wrap items-center gap-4 mb-6"><span class="flex items-center text-muted-foreground"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-calendar h-4 w-4 mr-1"><path d="M8 2v4"></path><path d="M16 2v4"></path><rect width="18" height="18" x="3" y="4" rx="2"></rect><path d="M3 10h18"></path></svg>May 6, 2025</span><span class="flex items-center text-muted-foreground"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-clock h-4 w-4 mr-1"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg>10 min read</span></div><div class="flex flex-wrap gap-2 mb-8"><a href="/blog/tag/deep-research"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground hover:bg-sky-50 cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag h-3 w-3 mr-1"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>Deep Research</div></a><a href="/blog/tag/bioacoustics"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground hover:bg-sky-50 cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag h-3 w-3 mr-1"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>bioacoustics</div></a><a href="/blog/tag/singapore"><div class="inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground hover:bg-sky-50 cursor-pointer"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-tag h-3 w-3 mr-1"><path d="M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z"></path><circle cx="7.5" cy="7.5" r=".5" fill="currentColor"></circle></svg>Singapore</div></a></div><div class="mb-8"><img src="/blogs/bird_call_singapore.png" alt="Singapore - Challenges and Progress in Bioacoustics" class="w-full rounded-lg"/></div><div class="prose prose-sky prose-img:rounded-xl prose-headings:scroll-mt-8 prose-a:text-sky-600 max-w-none sm:prose-lg"><h2>Introduction</h2>
<p>This report synthesizes the current literature on training bird sound classification models in data-sparse regional contexts with an emphasis on Singapore or similar Southeast Asian biodiversity hotspots. Overall, the reviewed literature indicates that while many studies develop robust machine learning frameworks using deep convolutional neural networks (CNNs), transfer learning, and semi-supervised techniques for bird sound classification, only a subset of these works explicitly focus on or have been evaluated using Singapore-specific soundscape recordings.</p>
<h2>1. General Frameworks and Methods in Data-Sparse Contexts</h2>
<p>A number of recent studies address the common challenges inherent in bioacoustic monitoring when labeled audio data are scarce. Researchers have proposed solutions that leverage transfer learning from large global datasets, employ data augmentation techniques, and utilize weak or semi-supervised learning approaches to overcome the limited availability of high-quality regional audio samples. For example, Bellafkir et al. (2023) describe a CNN-based approach that uses data augmentation methods such as the addition of background noise and selective mixup to mitigate class imbalances that naturally arise in long-tail distributions. Their methodology—developed originally for challenging soundscapes that include overlapping environmental noises and weak labels—is broadly applicable to scenarios with limited training data, such as those encountered in Southeast Asian urban and forest environments.</p>
<p>Deep transfer learning has been widely adopted to address the data limitation problem. Das et al. (2023) review various CNN architectures, including ResNet, Inception-v3, VGG, MobileNet, DenseNet, and EfficientNet, and detail how pre-trained networks (often on large-scale image or audio datasets) can be fine-tuned on much smaller regional datasets. These approaches considerably reduce the need for large quantities of labeled examples and decrease the training time while improving accuracy. Although the reviewed literature does not always include explicit evaluations using Singapore-specific data, the underlying methodologies show promise for adaptation to any data-sparse, biodiversity-rich region.</p>
<p>In addition to transfer learning, several groups have explored semi-supervised and weakly supervised approaches. For instance, Caprioli's (2022) work on semi-supervised classification using the FixMatch algorithm demonstrates that even with as few as 11 labeled samples per class, significant accuracy improvements can be attained compared to purely supervised baselines. These techniques are particularly relevant in contexts where field-collected labeled audio is extremely limited, such as in remote or urban ecosystems.</p>
<h2>2. Challenges in Contexts Like Singapore</h2>
<p>Many studies echo similar challenges in limited regional training data, especially when the targeted species are either rare or difficult to record. Common issues include:</p>
<ul>
<li>
<p><strong>Limited Availability of High-Quality Labeled Audio Data.</strong> In the field, particularly in highly diverse tropical settings like Singapore, obtaining long-duration recordings with high signal-to-noise ratios is challenging. Critically endangered or resident species often have very sparse recordings, and collector efforts are constrained by practical limitations as well as the fine-grained differences in acoustic patterns (Bellafkir et al., 2023).</p>
</li>
<li>
<p><strong>High Acoustic Similarity Among Coexisting Species.</strong> The coexistence of many species within a small geographical area results in considerable overlap in acoustic signals. This situation demands models that can differentiate subtle variations in call structure and temporal vocalization patterns, which in turn requires inventive signal processing and advanced network architectures capable of capturing both spectral and temporal features (Das et al., 2023).</p>
</li>
<li>
<p><strong>Environmental Noise and Overlapping Vocalizations.</strong> Urban and forest settings in Southeast Asia, including Singapore, are characterized by background noises from both natural and anthropogenic sources. This not only complicates the audio signal but also increases the chance of false positives. Several studies address these problems through sophisticated post-processing techniques, such as class-wise threshold calibrations and confidence penalization for overly common species (Bellafkir et al., 2023).</p>
</li>
</ul>
<h2>3. Efforts Focused on Singaporean Soundscapes</h2>
<p>When it comes to directly addressing the Singapore context, there is clear evidence of published work that has explicitly targeted Singapore's unique acoustic environment. Notably, Hexeberg et al. (2025) propose a semi-supervised classification approach for bird vocalizations that is explicitly tested using recordings from Singapore. Their work involves acoustic recordings from local sites—including the Singapore Botanic Gardens—collected over extended periods. This study demonstrates the feasibility of detecting species with overlapping vocalizations and noisy backgrounds in an urban tropical environment by achieving reasonable precision on classes even when trained on very few labeled samples. In further experiments, their classifier is shown to reflect natural diurnal and nocturnal behavioral patterns and to manage site-specific variations effectively. Such results provide strong validation that semi-supervised approaches can be adapted successfully to manage the synthesis of regional data in Singapore.</p>
<p>Additionally, while Bellafkir et al. (2023) do not explicitly test their model on Singapore data, they note that the efficiency of their pipeline in handling noisy, imbalanced, and weakly labeled datasets makes it well-suited for deployment in tropical urban and forest settings such as Singapore. Thus, although not every study targets Singapore directly, many proposed frameworks are clearly applicable to similar contexts in Southeast Asia.</p>
<p>Another indirect contribution comes from studies that have been conducted in neighboring regions—such as the SiulMalaya dataset for Malaysia—which similarly face challenges of high species diversity and background noise in lowland forests (Jamil et al., 2023). While the SiulMalaya dataset is specific to Malaysia, the underlying machine learning approaches can offer valuable insights for adapting models to the Singaporean context, given the ecological and acoustic similarities among tropical Southeast Asian habitats.</p>
<h2>4. Mitigation Strategies in Data-Sparse Settings</h2>
<p>Several strategies are recommended to address data scarcity in regional contexts such as Singapore:</p>
<ul>
<li>
<p><strong>Transfer Learning and Region-Specific Fine-Tuning.</strong> Numerous studies recommend using globally trained models and then fine-tuning them on localized, limited datasets. The use of pre-trained backbones such as EfficientNet (Ansar et al., 2024) and ResNet (Zhong et al., 2021) has been demonstrated to be beneficial when adapting to rare or underrepresented bird sounds. Although many works do not explicitly mention Singapore, the strategies described can be directly applied by incorporating local recording data during the fine-tuning stage.</p>
</li>
<li>
<p><strong>Semi-Supervised and Weakly-Supervised Learning.</strong> In environments where obtaining numerous labels is impractical, semi-supervised approaches that combine small amounts of labeled data with large volumes of unlabeled data provide a promising avenue. Hexeberg et al.'s (2025) work on semi-supervised classification in Singapore demonstrates that even with minimal labeled data, reasonable performance levels can be attained. Similarly, Caprioli's (2022) study on the FixMatch algorithm shows further improvements when pseudo-labels are generated from unlabeled recordings.</p>
</li>
<li>
<p><strong>Data Augmentation and Synthetic Data Generation.</strong> To supplement sparse datasets, augmentation methods such as time stretching, pitch shifting, and mixup are frequently applied. Bellafkir et al. (2023) incorporate several augmentation techniques designed to simulate the presence of background noise and overcome class imbalances. These practices are crucial in developing models that remain robust against the acoustic variability typical of urban and forested soundscapes in Singapore.</p>
</li>
</ul>
<h2>5. Gaps in the Current Literature</h2>
<p>While several frameworks have been successfully applied in data-sparse contexts throughout Southeast Asia, there remains a relative paucity of models that have been exclusively trained and validated on Singapore-specific data. Das et al. (2023) note that many deep transfer learning-based studies rely on datasets sourced from global repositories such as Xeno-canto and BirdCLEF, and that there is no explicit reference to Singaporean bird audio recordings within these published efforts. This observation highlights a meaningful gap in the literature: the need for dedicated Singapore-specific datasets and models that account for the unique acoustic challenges, species assemblages, and environmental characteristics within Singapore. Future work in this area could benefit from developing comprehensive local datasets, combining the strengths of both supervised and unsupervised methods, and leveraging metadata (e.g., spatial-temporal information) that might further differentiate the subtle acoustic nuances among local species.</p>
<h2>6. Conclusion</h2>
<p>In summary, while there is a substantial body of literature that presents methodologies for training bird sound classification models in data-sparse contexts, only select studies have directly tackled the Singapore setting. The work of Hexeberg et al. (2025) clearly demonstrates that a semi-supervised classification approach using Singapore-specific recordings is feasible even in the presence of noise, overlapping calls, and limited labels. Other frameworks developed by Bellafkir et al. (2023) and those based on deep transfer learning by Das et al. (2023) offer methods that are inherently adaptable to Singapore; however, they often rely on data not collected specifically from Singapore. The collective literature emphasizes the importance of harnessing advanced signal processing, ensemble learning, and fine-tuning strategies to address key challenges such as high species diversity, overlapping acoustic signals, and environmental noise. Although Singapore-specific efforts exist and show promising results, there remains a notable gap in published research dedicated solely to Singaporean bird song classification systems. Addressing this gap through continued development of localized data repositories and the adaptation of semi-supervised and transfer learning methods will enhance the accuracy and usability of these systems for biodiversity monitoring in tropical urban and forest contexts.</p>
<p>This review confirms that, indeed, there is published research concerning Singapore's bird sound classification – most notably the contributions by Hexeberg et al. (2025) – while many global models described in the literature provide methodologies that can be further extended and fine-tuned using local Singapore data. Continued efforts in integrating local recordings with established global models will ultimately lead to more accurate and region-sensitive bioacoustic monitoring systems in Southeast Asia.</p>
<h2>References</h2>
<p>Ansar, W., Chatterjee, A., Goswami, S., &#x26; Chakrabarti, A. (2024). An efficientnet-based ensemble for bird-call recognition with enhanced noise reduction. <em>SN Computer Science, 5</em>, 265. <a href="https://doi.org/10.1007/s42979-023-02591-6">https://doi.org/10.1007/s42979-023-02591-6</a></p>
<p>Bellafkir, H., Vogelbacher, M., Schneider, D., Kizik, V., Mühling, M., &#x26; Freisleben, B. (2023). Bird species recognition in soundscapes with self-supervised pre-training. <em>Communications in Computer and Information Science</em>, 60-74. <a href="https://doi.org/10.1007/978-3-031-46338-9_5">https://doi.org/10.1007/978-3-031-46338-9_5</a></p>
<p>Caprioli, E. (2022). <em>A semi-supervised approach to bird song classification</em> [Master's thesis, Norwegian University of Science and Technology]. NTNU Open. <a href="https://hdl.handle.net/11250/3093609">https://hdl.handle.net/11250/3093609</a></p>
<p>Das, N., Padhy, N., Dey, N., Bhattacharya, S., &#x26; Tavares, J. M. R. S. (2023). Deep transfer learning-based automated identification of bird song. <em>International Journal of Interactive Multimedia and Artificial Intelligence, 8</em>, 33. <a href="https://doi.org/10.9781/ijimai.2023.01.003">https://doi.org/10.9781/ijimai.2023.01.003</a></p>
<p>Hexeberg, S., Chitre, M., Hoffmann‐Kuhnt, M., &#x26; Low, B. W. (2025). Semi-supervised classification of bird vocalizations. <em>ArXiv</em>. <a href="https://doi.org/10.48550/arxiv.2502.13440">https://doi.org/10.48550/arxiv.2502.13440</a></p>
<p>Jamil, N., Norali, A. N., Ramli, M. I., Shah, A. K. M. K., &#x26; Mamat, I. (2023). Siulmalaya: an annotated bird audio dataset of malaysia lowland forest birds for passive acoustic monitoring. <em>Bulletin of Electrical Engineering and Informatics, 12</em>, 2269-2281. <a href="https://doi.org/10.11591/beei.v12i4.5243">https://doi.org/10.11591/beei.v12i4.5243</a></p>
<p>Zhong, M., Taylor, R., Bates, N., Christey, D., Basnet, H., Flippin, J., Palkovitz, S., Dodhia, R., &#x26; Ferres, J. L. (2021). Acoustic detection of regionally rare bird species through deep convolutional neural networks. <em>Ecological Informatics, 64</em>, 101333. <a href="https://doi.org/10.1016/j.ecoinf.2021.101333">https://doi.org/10.1016/j.ecoinf.2021.101333</a></p></div><div class="my-12"><div class="rounded-lg border text-card-foreground shadow-sm bg-green-50 border-green-100"><div class="p-6"><div class="text-center max-w-xl mx-auto"><h3 class="text-xl font-bold mb-2">Stay Updated</h3><p class="text-muted-foreground mb-4">Subscribe to our newsletter to receive new articles and updates directly in your inbox.</p><form class="max-w-md mx-auto"><div class="flex gap-2"><div class="relative flex-grow"><input type="email" class="flex h-10 w-full rounded-md border border-input px-3 py-2 text-base ring-offset-background file:border-0 file:bg-transparent file:text-sm file:font-medium file:text-foreground placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:cursor-not-allowed disabled:opacity-50 md:text-sm pl-9 bg-white" placeholder="Your email" required="" value=""/><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mail absolute left-3 top-1/2 transform -translate-y-1/2 h-4 w-4 text-muted-foreground"><rect width="20" height="16" x="2" y="4" rx="2"></rect><path d="m22 7-8.97 5.7a1.94 1.94 0 0 1-2.06 0L2 7"></path></svg></div><button class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 text-primary-foreground h-10 px-4 py-2 bg-green-500 hover:bg-green-600 flex-shrink-0" type="submit">Subscribe</button></div></form></div></div></div></div></div></div></div></div><footer class="py-8 border-t"><div class="container mx-auto px-4"><div class="flex flex-col md:flex-row justify-between items-center gap-6"><div class="flex flex-col items-center md:items-start"><div class="flex items-center gap-2 mb-2"><div class="w-8 h-8 rounded-full overflow-hidden mr-2"><img alt="SingBirds Logo" loading="lazy" width="32" height="32" decoding="async" data-nimg="1" class="w-full h-full object-cover" style="color:transparent" src="/pitta-gpt.png"/></div><h3 class="text-xl font-bold gradient-text">SingBirds</h3></div><p class="text-sm text-muted-foreground text-center md:text-left">I Code Birds.</p></div><div class="flex gap-4"><a href="https://github.com/fairy-pitta" target="_blank" rel="noopener noreferrer" class="text-muted-foreground hover:text-sky-500 transition-colors" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-github h-6 w-6"><path d="M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4"></path><path d="M9 18c-4.51 2-5-2-7-2"></path></svg></a></div></div><div class="border-t mt-6 pt-6 flex flex-col md:flex-row justify-between items-center gap-4"><div class="text-sm text-muted-foreground">© <!-- -->2025<!-- --> SingBirds. All rights reserved.</div><div class="flex gap-6 text-sm"><a href="/privacy" class="text-muted-foreground hover:text-sky-500 transition-colors">Privacy Policy</a><a href="/terms" class="text-muted-foreground hover:text-sky-500 transition-colors">Terms of Service</a></div></div></div></footer><script src="/_next/static/chunks/webpack-84be5e7f048f0d69.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[9304,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"static/chunks/497-8f454888f232b3fa.js\",\"766\",\"static/chunks/766-98bd1540b448b2b9.js\",\"177\",\"static/chunks/app/layout-83c85cf5db64605f.js\"],\"ThemeProvider\"]\n3:I[9578,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"static/chunks/497-8f454888f232b3fa.js\",\"766\",\"static/chunks/766-98bd1540b448b2b9.js\",\"177\",\"static/chunks/app/layout-83c85cf5db64605f.js\"],\"default\"]\n4:I[7555,[],\"\"]\n5:I[1295,[],\"\"]\n6:I[3063,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"static/chunks/497-8f454888f232b3fa.js\",\"766\",\"static/chunks/766-98bd1540b448b2b9.js\",\"177\",\"static/chunks/app/layout-83c85cf5db64605f.js\"],\"Image\"]\n8:I[9665,[],\"OutletBoundary\"]\nb:I[9665,[],\"ViewportBoundary\"]\nd:I[9665,[],\"MetadataBoundary\"]\nf:I[6614,[],\"\"]\n:HL[\"/_next/static/media/a34f9d1faa5f3315-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/730b9168ceaa3868.css\",\"style\"]\n:HL[\"/_next/static/css/b3cbcd051438d1d5.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"nli5VSm0dNMiC8p1OoAct\",\"p\":\"\",\"c\":[\"\",\"blog\",\"bird-sound-classification-in-singapore\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"blog\",{\"children\":[[\"slug\",\"bird-sound-classification-in-singapore\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/730b9168ceaa3868.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/b3cbcd051438d1d5.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"suppressHydrationWarning\":true,\"children\":[\"$\",\"body\",null,{\"className\":\"__className_d65c78\",\"children\":[\"$\",\"$L2\",null,{\"attribute\":\"class\",\"defaultTheme\":\"light\",\"enableSystem\":false,\"disableTransitionOnChange\":true,\"children\":[[\"$\",\"$L3\",null,{}],[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"footer\",null,{\"className\":\"py-8 border-t\",\"children\":[\"$\",\"div\",null,{\"className\":\"container mx-auto px-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-col md:flex-row justify-between items-center gap-6\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-col items-center md:items-start\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-center gap-2 mb-2\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-8 h-8 rounded-full overflow-hidden mr-2\",\"children\":[\"$\",\"$L6\",null,{\"src\":\"/pitta-gpt.png\",\"alt\":\"SingBirds Logo\",\"width\":32,\"height\":32,\"className\":\"w-full h-full object-cover\"}]}],[\"$\",\"h3\",null,{\"className\":\"text-xl font-bold gradient-text\",\"children\":\"SingBirds\"}]]}],[\"$\",\"p\",null,{\"className\":\"text-sm text-muted-foreground text-center md:text-left\",\"children\":\"I Code Birds.\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex gap-4\",\"children\":[\"$\",\"a\",null,{\"href\":\"https://github.com/fairy-pitta\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"className\":\"text-muted-foreground hover:text-sky-500 transition-colors\",\"aria-label\":\"GitHub\",\"children\":[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-github h-6 w-6\",\"children\":[[\"$\",\"path\",\"tonef\",{\"d\":\"M15 22v-4a4.8 4.8 0 0 0-1-3.5c3 0 6-2 6-5.5.08-1.25-.27-2.48-1-3.5.28-1.15.28-2.35 0-3.5 0 0-1 0-3 1.5-2.64-.5-5.36-.5-8 0C6 2 5 2 5 2c-.3 1.15-.3 2.35 0 3.5A5.403 5.403 0 0 0 4 9c0 3.5 3 5.5 6 5.5-.39.49-.68 1.05-.85 1.65-.17.6-.22 1.23-.15 1.85v4\"}],[\"$\",\"path\",\"9comsn\",{\"d\":\"M9 18c-4.51 2-5-2-7-2\"}],\"$undefined\"]}]}]}]]}],[\"$\",\"div\",null,{\"className\":\"border-t mt-6 pt-6 flex flex-col md:flex-row justify-between items-center gap-4\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-sm text-muted-foreground\",\"children\":[\"© \",2025,\" SingBirds. All rights reserved.\"]}],[\"$\",\"div\",null,{\"className\":\"flex gap-6 text-sm\",\"children\":[[\"$\",\"a\",null,{\"href\":\"/privacy\",\"className\":\"text-muted-foreground hover:text-sky-500 transition-colors\",\"children\":\"Privacy Policy\"}],[\"$\",\"a\",null,{\"href\":\"/terms\",\"className\":\"text-muted-foreground hover:text-sky-500 transition-colors\",\"children\":\"Terms of Service\"}]]}]]}]]}]}]]}]}]}]]}],{\"children\":[\"blog\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"bird-sound-classification-in-singapore\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L7\",\"$undefined\",null,[\"$\",\"$L8\",null,{\"children\":[\"$L9\",\"$La\",null]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"XmBCsJb3RSI3wiT9ixs6A\",{\"children\":[[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$f\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"c:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n9:null\n"])</script><script>self.__next_f.push([1,"10:I[3440,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"static/chunks/497-8f454888f232b3fa.js\",\"663\",\"static/chunks/663-bf703af64886d2e2.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-fbcb4166984d1917.js\"],\"default\"]\n11:I[6874,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"static/chunks/497-8f454888f232b3fa.js\",\"663\",\"static/chunks/663-bf703af64886d2e2.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-fbcb4166984d1917.js\"],\"\"]\n13:I[2776,[\"874\",\"static/chunks/874-564943c90346e675.js\",\"497\",\"static/chunks/497-8f454888f232b3fa.js\",\"663\",\"static/chunks/663-bf703af64886d2e2.js\",\"953\",\"static/chunks/app/blog/%5Bslug%5D/page-fbcb4166984d1917.js\"],\"default\"]\n12:T361f,"])</script><script>self.__next_f.push([1,"\u003ch2\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eThis report synthesizes the current literature on training bird sound classification models in data-sparse regional contexts with an emphasis on Singapore or similar Southeast Asian biodiversity hotspots. Overall, the reviewed literature indicates that while many studies develop robust machine learning frameworks using deep convolutional neural networks (CNNs), transfer learning, and semi-supervised techniques for bird sound classification, only a subset of these works explicitly focus on or have been evaluated using Singapore-specific soundscape recordings.\u003c/p\u003e\n\u003ch2\u003e1. General Frameworks and Methods in Data-Sparse Contexts\u003c/h2\u003e\n\u003cp\u003eA number of recent studies address the common challenges inherent in bioacoustic monitoring when labeled audio data are scarce. Researchers have proposed solutions that leverage transfer learning from large global datasets, employ data augmentation techniques, and utilize weak or semi-supervised learning approaches to overcome the limited availability of high-quality regional audio samples. For example, Bellafkir et al. (2023) describe a CNN-based approach that uses data augmentation methods such as the addition of background noise and selective mixup to mitigate class imbalances that naturally arise in long-tail distributions. Their methodology—developed originally for challenging soundscapes that include overlapping environmental noises and weak labels—is broadly applicable to scenarios with limited training data, such as those encountered in Southeast Asian urban and forest environments.\u003c/p\u003e\n\u003cp\u003eDeep transfer learning has been widely adopted to address the data limitation problem. Das et al. (2023) review various CNN architectures, including ResNet, Inception-v3, VGG, MobileNet, DenseNet, and EfficientNet, and detail how pre-trained networks (often on large-scale image or audio datasets) can be fine-tuned on much smaller regional datasets. These approaches considerably reduce the need for large quantities of labeled examples and decrease the training time while improving accuracy. Although the reviewed literature does not always include explicit evaluations using Singapore-specific data, the underlying methodologies show promise for adaptation to any data-sparse, biodiversity-rich region.\u003c/p\u003e\n\u003cp\u003eIn addition to transfer learning, several groups have explored semi-supervised and weakly supervised approaches. For instance, Caprioli's (2022) work on semi-supervised classification using the FixMatch algorithm demonstrates that even with as few as 11 labeled samples per class, significant accuracy improvements can be attained compared to purely supervised baselines. These techniques are particularly relevant in contexts where field-collected labeled audio is extremely limited, such as in remote or urban ecosystems.\u003c/p\u003e\n\u003ch2\u003e2. Challenges in Contexts Like Singapore\u003c/h2\u003e\n\u003cp\u003eMany studies echo similar challenges in limited regional training data, especially when the targeted species are either rare or difficult to record. Common issues include:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eLimited Availability of High-Quality Labeled Audio Data.\u003c/strong\u003e In the field, particularly in highly diverse tropical settings like Singapore, obtaining long-duration recordings with high signal-to-noise ratios is challenging. Critically endangered or resident species often have very sparse recordings, and collector efforts are constrained by practical limitations as well as the fine-grained differences in acoustic patterns (Bellafkir et al., 2023).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eHigh Acoustic Similarity Among Coexisting Species.\u003c/strong\u003e The coexistence of many species within a small geographical area results in considerable overlap in acoustic signals. This situation demands models that can differentiate subtle variations in call structure and temporal vocalization patterns, which in turn requires inventive signal processing and advanced network architectures capable of capturing both spectral and temporal features (Das et al., 2023).\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eEnvironmental Noise and Overlapping Vocalizations.\u003c/strong\u003e Urban and forest settings in Southeast Asia, including Singapore, are characterized by background noises from both natural and anthropogenic sources. This not only complicates the audio signal but also increases the chance of false positives. Several studies address these problems through sophisticated post-processing techniques, such as class-wise threshold calibrations and confidence penalization for overly common species (Bellafkir et al., 2023).\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e3. Efforts Focused on Singaporean Soundscapes\u003c/h2\u003e\n\u003cp\u003eWhen it comes to directly addressing the Singapore context, there is clear evidence of published work that has explicitly targeted Singapore's unique acoustic environment. Notably, Hexeberg et al. (2025) propose a semi-supervised classification approach for bird vocalizations that is explicitly tested using recordings from Singapore. Their work involves acoustic recordings from local sites—including the Singapore Botanic Gardens—collected over extended periods. This study demonstrates the feasibility of detecting species with overlapping vocalizations and noisy backgrounds in an urban tropical environment by achieving reasonable precision on classes even when trained on very few labeled samples. In further experiments, their classifier is shown to reflect natural diurnal and nocturnal behavioral patterns and to manage site-specific variations effectively. Such results provide strong validation that semi-supervised approaches can be adapted successfully to manage the synthesis of regional data in Singapore.\u003c/p\u003e\n\u003cp\u003eAdditionally, while Bellafkir et al. (2023) do not explicitly test their model on Singapore data, they note that the efficiency of their pipeline in handling noisy, imbalanced, and weakly labeled datasets makes it well-suited for deployment in tropical urban and forest settings such as Singapore. Thus, although not every study targets Singapore directly, many proposed frameworks are clearly applicable to similar contexts in Southeast Asia.\u003c/p\u003e\n\u003cp\u003eAnother indirect contribution comes from studies that have been conducted in neighboring regions—such as the SiulMalaya dataset for Malaysia—which similarly face challenges of high species diversity and background noise in lowland forests (Jamil et al., 2023). While the SiulMalaya dataset is specific to Malaysia, the underlying machine learning approaches can offer valuable insights for adapting models to the Singaporean context, given the ecological and acoustic similarities among tropical Southeast Asian habitats.\u003c/p\u003e\n\u003ch2\u003e4. Mitigation Strategies in Data-Sparse Settings\u003c/h2\u003e\n\u003cp\u003eSeveral strategies are recommended to address data scarcity in regional contexts such as Singapore:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eTransfer Learning and Region-Specific Fine-Tuning.\u003c/strong\u003e Numerous studies recommend using globally trained models and then fine-tuning them on localized, limited datasets. The use of pre-trained backbones such as EfficientNet (Ansar et al., 2024) and ResNet (Zhong et al., 2021) has been demonstrated to be beneficial when adapting to rare or underrepresented bird sounds. Although many works do not explicitly mention Singapore, the strategies described can be directly applied by incorporating local recording data during the fine-tuning stage.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eSemi-Supervised and Weakly-Supervised Learning.\u003c/strong\u003e In environments where obtaining numerous labels is impractical, semi-supervised approaches that combine small amounts of labeled data with large volumes of unlabeled data provide a promising avenue. Hexeberg et al.'s (2025) work on semi-supervised classification in Singapore demonstrates that even with minimal labeled data, reasonable performance levels can be attained. Similarly, Caprioli's (2022) study on the FixMatch algorithm shows further improvements when pseudo-labels are generated from unlabeled recordings.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eData Augmentation and Synthetic Data Generation.\u003c/strong\u003e To supplement sparse datasets, augmentation methods such as time stretching, pitch shifting, and mixup are frequently applied. Bellafkir et al. (2023) incorporate several augmentation techniques designed to simulate the presence of background noise and overcome class imbalances. These practices are crucial in developing models that remain robust against the acoustic variability typical of urban and forested soundscapes in Singapore.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e5. Gaps in the Current Literature\u003c/h2\u003e\n\u003cp\u003eWhile several frameworks have been successfully applied in data-sparse contexts throughout Southeast Asia, there remains a relative paucity of models that have been exclusively trained and validated on Singapore-specific data. Das et al. (2023) note that many deep transfer learning-based studies rely on datasets sourced from global repositories such as Xeno-canto and BirdCLEF, and that there is no explicit reference to Singaporean bird audio recordings within these published efforts. This observation highlights a meaningful gap in the literature: the need for dedicated Singapore-specific datasets and models that account for the unique acoustic challenges, species assemblages, and environmental characteristics within Singapore. Future work in this area could benefit from developing comprehensive local datasets, combining the strengths of both supervised and unsupervised methods, and leveraging metadata (e.g., spatial-temporal information) that might further differentiate the subtle acoustic nuances among local species.\u003c/p\u003e\n\u003ch2\u003e6. Conclusion\u003c/h2\u003e\n\u003cp\u003eIn summary, while there is a substantial body of literature that presents methodologies for training bird sound classification models in data-sparse contexts, only select studies have directly tackled the Singapore setting. The work of Hexeberg et al. (2025) clearly demonstrates that a semi-supervised classification approach using Singapore-specific recordings is feasible even in the presence of noise, overlapping calls, and limited labels. Other frameworks developed by Bellafkir et al. (2023) and those based on deep transfer learning by Das et al. (2023) offer methods that are inherently adaptable to Singapore; however, they often rely on data not collected specifically from Singapore. The collective literature emphasizes the importance of harnessing advanced signal processing, ensemble learning, and fine-tuning strategies to address key challenges such as high species diversity, overlapping acoustic signals, and environmental noise. Although Singapore-specific efforts exist and show promising results, there remains a notable gap in published research dedicated solely to Singaporean bird song classification systems. Addressing this gap through continued development of localized data repositories and the adaptation of semi-supervised and transfer learning methods will enhance the accuracy and usability of these systems for biodiversity monitoring in tropical urban and forest contexts.\u003c/p\u003e\n\u003cp\u003eThis review confirms that, indeed, there is published research concerning Singapore's bird sound classification – most notably the contributions by Hexeberg et al. (2025) – while many global models described in the literature provide methodologies that can be further extended and fine-tuned using local Singapore data. Continued efforts in integrating local recordings with established global models will ultimately lead to more accurate and region-sensitive bioacoustic monitoring systems in Southeast Asia.\u003c/p\u003e\n\u003ch2\u003eReferences\u003c/h2\u003e\n\u003cp\u003eAnsar, W., Chatterjee, A., Goswami, S., \u0026#x26; Chakrabarti, A. (2024). An efficientnet-based ensemble for bird-call recognition with enhanced noise reduction. \u003cem\u003eSN Computer Science, 5\u003c/em\u003e, 265. \u003ca href=\"https://doi.org/10.1007/s42979-023-02591-6\"\u003ehttps://doi.org/10.1007/s42979-023-02591-6\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eBellafkir, H., Vogelbacher, M., Schneider, D., Kizik, V., Mühling, M., \u0026#x26; Freisleben, B. (2023). Bird species recognition in soundscapes with self-supervised pre-training. \u003cem\u003eCommunications in Computer and Information Science\u003c/em\u003e, 60-74. \u003ca href=\"https://doi.org/10.1007/978-3-031-46338-9_5\"\u003ehttps://doi.org/10.1007/978-3-031-46338-9_5\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eCaprioli, E. (2022). \u003cem\u003eA semi-supervised approach to bird song classification\u003c/em\u003e [Master's thesis, Norwegian University of Science and Technology]. NTNU Open. \u003ca href=\"https://hdl.handle.net/11250/3093609\"\u003ehttps://hdl.handle.net/11250/3093609\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eDas, N., Padhy, N., Dey, N., Bhattacharya, S., \u0026#x26; Tavares, J. M. R. S. (2023). Deep transfer learning-based automated identification of bird song. \u003cem\u003eInternational Journal of Interactive Multimedia and Artificial Intelligence, 8\u003c/em\u003e, 33. \u003ca href=\"https://doi.org/10.9781/ijimai.2023.01.003\"\u003ehttps://doi.org/10.9781/ijimai.2023.01.003\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eHexeberg, S., Chitre, M., Hoffmann‐Kuhnt, M., \u0026#x26; Low, B. W. (2025). Semi-supervised classification of bird vocalizations. \u003cem\u003eArXiv\u003c/em\u003e. \u003ca href=\"https://doi.org/10.48550/arxiv.2502.13440\"\u003ehttps://doi.org/10.48550/arxiv.2502.13440\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eJamil, N., Norali, A. N., Ramli, M. I., Shah, A. K. M. K., \u0026#x26; Mamat, I. (2023). Siulmalaya: an annotated bird audio dataset of malaysia lowland forest birds for passive acoustic monitoring. \u003cem\u003eBulletin of Electrical Engineering and Informatics, 12\u003c/em\u003e, 2269-2281. \u003ca href=\"https://doi.org/10.11591/beei.v12i4.5243\"\u003ehttps://doi.org/10.11591/beei.v12i4.5243\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eZhong, M., Taylor, R., Bates, N., Christey, D., Basnet, H., Flippin, J., Palkovitz, S., Dodhia, R., \u0026#x26; Ferres, J. L. (2021). Acoustic detection of regionally rare bird species through deep convolutional neural networks. \u003cem\u003eEcological Informatics, 64\u003c/em\u003e, 101333. \u003ca href=\"https://doi.org/10.1016/j.ecoinf.2021.101333\"\u003ehttps://doi.org/10.1016/j.ecoinf.2021.101333\u003c/a\u003e\u003c/p\u003e"])</script><script>self.__next_f.push([1,"7:[\"$\",\"$L10\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"min-h-screen bg-background\",\"children\":[\"$\",\"div\",null,{\"className\":\"pt-14 md:pt-16\",\"children\":[\"$\",\"div\",null,{\"className\":\"container mx-auto px-4 py-12\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-3xl mx-auto\",\"children\":[[\"$\",\"$L11\",null,{\"href\":\"/blog\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-arrow-left h-4 w-4 mr-2\",\"children\":[[\"$\",\"path\",\"1l729n\",{\"d\":\"m12 19-7-7 7-7\"}],[\"$\",\"path\",\"x3x0zl\",{\"d\":\"M19 12H5\"}],\"$undefined\"]}],\"Back to Blog\"],\"className\":\"inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 [\u0026_svg]:pointer-events-none [\u0026_svg]:size-4 [\u0026_svg]:shrink-0 hover:bg-accent hover:text-accent-foreground h-10 px-4 py-2 mb-6\",\"ref\":null}],[\"$\",\"h1\",null,{\"className\":\"text-3xl md:text-4xl font-bold mb-4\",\"children\":\"Singapore - Challenges and Progress in Bioacoustics\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-4 mb-6\",\"children\":[[\"$\",\"span\",null,{\"className\":\"flex items-center text-muted-foreground\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-calendar h-4 w-4 mr-1\",\"children\":[[\"$\",\"path\",\"1cmpym\",{\"d\":\"M8 2v4\"}],[\"$\",\"path\",\"4m81vk\",{\"d\":\"M16 2v4\"}],[\"$\",\"rect\",\"1hopcy\",{\"width\":\"18\",\"height\":\"18\",\"x\":\"3\",\"y\":\"4\",\"rx\":\"2\"}],[\"$\",\"path\",\"8toen8\",{\"d\":\"M3 10h18\"}],\"$undefined\"]}],\"May 6, 2025\"]}],[\"$\",\"span\",null,{\"className\":\"flex items-center text-muted-foreground\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-clock h-4 w-4 mr-1\",\"children\":[[\"$\",\"circle\",\"1mglay\",{\"cx\":\"12\",\"cy\":\"12\",\"r\":\"10\"}],[\"$\",\"polyline\",\"68esgv\",{\"points\":\"12 6 12 12 16 14\"}],\"$undefined\"]}],\"10 min read\"]}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2 mb-8\",\"children\":[[\"$\",\"$L11\",\"Deep Research\",{\"href\":\"/blog/tag/deep-research\",\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground hover:bg-sky-50 cursor-pointer\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-tag h-3 w-3 mr-1\",\"children\":[[\"$\",\"path\",\"vktsd0\",{\"d\":\"M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z\"}],[\"$\",\"circle\",\"kqv944\",{\"cx\":\"7.5\",\"cy\":\"7.5\",\"r\":\".5\",\"fill\":\"currentColor\"}],\"$undefined\"]}],\"Deep Research\"]}]}],[\"$\",\"$L11\",\"bioacoustics\",{\"href\":\"/blog/tag/bioacoustics\",\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground hover:bg-sky-50 cursor-pointer\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-tag h-3 w-3 mr-1\",\"children\":[[\"$\",\"path\",\"vktsd0\",{\"d\":\"M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z\"}],[\"$\",\"circle\",\"kqv944\",{\"cx\":\"7.5\",\"cy\":\"7.5\",\"r\":\".5\",\"fill\":\"currentColor\"}],\"$undefined\"]}],\"bioacoustics\"]}]}],[\"$\",\"$L11\",\"Singapore\",{\"href\":\"/blog/tag/singapore\",\"children\":[\"$\",\"div\",null,{\"className\":\"inline-flex items-center rounded-full border px-2.5 py-0.5 text-xs font-semibold transition-colors focus:outline-none focus:ring-2 focus:ring-ring focus:ring-offset-2 text-foreground hover:bg-sky-50 cursor-pointer\",\"children\":[[\"$\",\"svg\",null,{\"ref\":\"$undefined\",\"xmlns\":\"http://www.w3.org/2000/svg\",\"width\":24,\"height\":24,\"viewBox\":\"0 0 24 24\",\"fill\":\"none\",\"stroke\":\"currentColor\",\"strokeWidth\":2,\"strokeLinecap\":\"round\",\"strokeLinejoin\":\"round\",\"className\":\"lucide lucide-tag h-3 w-3 mr-1\",\"children\":[[\"$\",\"path\",\"vktsd0\",{\"d\":\"M12.586 2.586A2 2 0 0 0 11.172 2H4a2 2 0 0 0-2 2v7.172a2 2 0 0 0 .586 1.414l8.704 8.704a2.426 2.426 0 0 0 3.42 0l6.58-6.58a2.426 2.426 0 0 0 0-3.42z\"}],[\"$\",\"circle\",\"kqv944\",{\"cx\":\"7.5\",\"cy\":\"7.5\",\"r\":\".5\",\"fill\":\"currentColor\"}],\"$undefined\"]}],\"Singapore\"]}]}]]}],[\"$\",\"div\",null,{\"className\":\"mb-8\",\"children\":[\"$\",\"img\",null,{\"src\":\"/blogs/bird_call_singapore.png\",\"alt\":\"Singapore - Challenges and Progress in Bioacoustics\",\"className\":\"w-full rounded-lg\"}]}],[\"$\",\"div\",null,{\"className\":\"prose prose-sky prose-img:rounded-xl prose-headings:scroll-mt-8 prose-a:text-sky-600 max-w-none sm:prose-lg\",\"dangerouslySetInnerHTML\":{\"__html\":\"$12\"}}],[\"$\",\"div\",null,{\"className\":\"my-12\",\"children\":[\"$\",\"$L13\",null,{}]}]]}]}]}]}]}]\n"])</script><script>self.__next_f.push([1,"a:null\ne:[[\"$\",\"title\",\"0\",{\"children\":\"Singapore - Challenges and Progress in Bioacoustics | SingBirds\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"A quick look at the bioacoustics challenges in Singapore\"}],[\"$\",\"meta\",\"2\",{\"name\":\"application-name\",\"content\":\"SingBirds\"}],[\"$\",\"meta\",\"3\",{\"name\":\"author\",\"content\":\"SingBirds\"}],[\"$\",\"meta\",\"4\",{\"name\":\"generator\",\"content\":\"v0.dev\"}],[\"$\",\"link\",\"5\",{\"rel\":\"shortcut icon\",\"href\":\"/favicon.ico\"}],[\"$\",\"link\",\"6\",{\"rel\":\"icon\",\"href\":\"/fairy-pitta.png\"}],[\"$\",\"link\",\"7\",{\"rel\":\"apple-touch-icon\",\"href\":\"/apple-icon.png\"}]]\n"])</script></body></html>